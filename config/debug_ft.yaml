run_dir: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/hp_v2/
exp_name: test_ft


continuation: 0.0
textual_continuation: 0.0

lora_llm:
  enable: false
  rank: 128
  scaling: 2.0

lora_embedder:
  enable: false
  rank: 128
  scaling: 2.0

embedder_path: /lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B
llm_path: /lustre/scwpod02/client/kyutai-interns/hippop/models/Llama3.2-3B
# Llama3.1-8B  Llama3.2-3B
llm_type: llama
num_microbatches: 1

optim:
  final_lr: 1.0e-10
  initial_lr: 1.0e-20
  max_lr: 1.0e-06
  warm_up_steps: 500
  weight_decay: 0.1

pipeline:
  embedder_params:
    causal_embedder: true
    compress_rates:
    - -16
    n_truncated_layers: 16
    pooling_module:
      pool_type: mean_sa
      where: before
    trained_layers: 4
    rec_tok: true
    mixed_method: true
    memory_tokens: 128
  max_embeds: 1
  w_embeds: true
  bridge_module:
    bridge_type: mlp
    in_dim: 4096
    hidden_dim: 2048
    out_dim: 3072

from_ckpt:
  do: true
  bridge_path: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/hp_v2/test_pretrain/checkpoints/checkpoint_000010/bridge_module
  embedder_path: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/hp_v2/test_pretrain/checkpoints/checkpoint_000010/embedder/

data:
  adapt_seq_len: true
  eval_data: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/eval_ReadComp/squad_test.jsonl
  shuffle: false
  train_data: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/instruct_data/Reading_Comp/squad_v2_only_answered.jsonl


seq_len: 1024
max_seq_len: 2048
batch_size: 4
num_microbatches: 1
max_steps: 1000


seed: 0
log_freq: 1
eval_freq: 50
no_eval: false
ckpt_freq: 30

# SQUAD: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/instruct_data/Reading_Comp/squad_v2_only_answered.jsonl
# NQ, TRIVIAQA: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/instruct_data/QA_w_retrieved_passages_NVEmbed/  nq_open_data.jsonl, triviaqa_data.jsonl



