model_id_or_path: /lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B
llm_name: Mistral7B
run_dir: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/
exp_name: test_instruct
start_from_ckpt_path: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/test_pretrain/checkpoints/checkpoint_000010

lora:
  rank: 64
  scaling: 2.0
  enable: true


instruct_tuning:
  do: true
  cross_entropy: true
  kl: true
  alpha: 2.0
  temp: 1.0
  tune_llm: true
  tune_embedder: true


data:
  # train_data: /lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_train.jsonl
  eval_data: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/instruct_data/test_instruct.jsonl
  shuffle: false
  train_data: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/instruct_data/test_instruct.jsonl
  data_types: [instruct]
  adapt_seq_len: true

seq_len: 128
batch_size: 32
num_microbatches: 1
max_steps: 20000
optim:
  max_lr: 5.0e-05
  weight_decay: 0.1
  warm_up_steps: 500
  initial_lr: 1.0e-20
  final_lr: 1.0e-10
seed: 0
log_freq: 10
eval_freq: 100
no_eval: true
ckpt_freq: 500
save_adapters: true

# wandb:
#   project: embed_llm
#   run_name: LT_FN_False_1_MLP_Latt_True_CA_2_CAL_every_True_DB
#   key: 79d15dbc90cdc10b0d5e5ad252ae8ddbef9fd706
#   offline: false


