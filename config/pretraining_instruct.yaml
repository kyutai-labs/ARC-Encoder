data:
  eval_data: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/crawl/eval_en_00_of_18.jsonl
  shuffle: false
  train_data: /lustre/scwpod02/client/kyutai-interns/datasets/crawl_2/train_en_00_of_18.jsonl
  n_eval_batches: 5
  instruct_decoder: true
  
run_dir: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/hp_v2/
llm_paths:  
  - /lustre/scwpod02/client/kyutai-interns/hippop/models/Llama2-7B-Chat
llm_types: 
  - llama_2
embedder_path: /lustre/scwpod02/client/kyutai-interns/hippop/models/Llama3.2-3B
embed_type: llama
num_microbatches: 1
seed: 0
max_steps: 80000
seq_len: 256
log_freq: 10
batch_size: 16
ckpt_freq: 5000
eval_freq: 50
no_eval: false
continuation: 0.8
optim:
  final_lr: 1.0e-10
  initial_lr: 1.0e-20
  max_lr: 1.0e-05
  max_lr_projector: 5.0e-05
  warm_up_steps: 1000
  weight_decay: 0.1
pipeline:
  embedder_params:
    causal_embedder: false
    compress_rates:
    - -8
    n_truncated_layers: 2
    pooling_module:
      pool_type: mean_pooled_queries
      where: before
    trained_layers: 27
    train_embedding_mtx: true
    rec_tok: False
    cont_tok: False
  bridge_module:
    bridge_type: mlp
    in_dim: 3072
    hidden_dim: 2048
    out_dim: 4096
num_ckpt_keep: 2
exp_name: instruct_test
# wandb:
#   key: 79d15dbc90cdc10b0d5e5ad252ae8ddbef9fd706
#   offline: false
#   project: embed_llm
#   run_name: Instruct_CP8_long_pt
