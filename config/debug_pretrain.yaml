model_id_or_path: /lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B
llm_name: Mistral7B
run_dir: /lustre/scwpod02/client/kyutai-interns/hippop/tmp/
exp_name: test_pretrain
continuation: 1.0

lora:
  enable: false
  rank: 128
  scaling: 2.0
  
model_id_or_path: /lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B
no_eval: false
num_microbatches: 1
optim:
  final_lr: 1.0e-10
  initial_lr: 1.0e-20
  max_lr: 5.0e-05
  warm_up_steps: 500
  weight_decay: 0.1

pipeline:
  do_pool: true
  embedder_name: Mistral7B
  mlp_project:
    act: gelu
    hidden_dim: 4096
    n_layers: 1
    type: mlp
    first_rms_norm: true
  n_truncated_layers: 16
  pooling_module:
    compress_rate: -8
    type: adaptive_attention
    pool_type: post_sfmx_mean_mta
    cont_att_norm: true
    post_sftmx: true
  train_only_pooling: true
  w_embeds: true  
  causal_embedder: true



data:
  adapt_seq_len: false
  eval_data: /lustre/scwpod02/client/kyutai-interns/hippop/processed_data/crawl/eval_en_00_of_18.jsonl
  shuffle: false
  train_data: /lustre/scwpod02/client/kyutai-interns/datasets/crawl_2/train_en_00_of_18.jsonl


seq_len: 256
batch_size: 16
num_microbatches: 1
max_steps: 50
optim:
  max_lr: 5.0e-05
  weight_decay: 0.1
  warm_up_steps: 2
  initial_lr: 1.0e-20
  final_lr: 1.0e-10

seed: 0
log_freq: 1
eval_freq: 50
no_eval: false
ckpt_freq: 500
save_adapters: true


# wandb:
#   project: embed_llm
#   run_name: pretrain_both_trained_07_singpassage_0f6f2a1a
#   key: 79d15dbc90cdc10b0d5e5ad252ae8ddbef9fd706
#   offline: false




