{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippolytepilchen/micromamba/envs/llm_embed/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from embed_llm.models.augmented_model import EmbedAugPipeline\n",
    "from embed_llm.generation.evaluation import word_overlap, get_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 29\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w_embeds': True, 'norm_wo_embeds': False, 'mlp_project': {'hidden_dim': 4096, 'n_layers': 0, 'act': 'gelu', 'in_dim': 4096, 'out_dim': 4096}, 'training': True, 'param_dtype': 'float32', 'embedder_name': 'NVEmbed', 'trainable_embedder': False, 'causal': True, 'do_pool': True, 'n_truncated_layers': 4, 'normalize_embeddings': True, 'pooling_module': {'type': 'eos', 'r': 512, 'n_heads': 8, 'n_layers': 1}, 'continuation': False, 'shared_kv': True, 'cross_att': False, 'cross_att_layers': 5, 'do_both': False}\n"
     ]
    }
   ],
   "source": [
    "llm_path = '/lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B'\n",
    "#Must have a params json for pipeline\n",
    "\n",
    "# Finished runs:\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_16_CAL_False_SKV_True_DB'\n",
    "run_name = '128_SL_FN_False_0_MLP_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_24_CAL_False_SKV_True_DB'\n",
    "\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_False_0_MLP_False_CA_False_DB'\n",
    "\n",
    "\n",
    "\n",
    "ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/' + run_name \n",
    "\n",
    "with open(f'{ckpt_path}'+ '/checkpoints/checkpoint_010000/params.json') as f:\n",
    "    params = json.load(f)\n",
    "print(params)\n",
    "\n",
    "model_name = 'Mistral7B' \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "w_embeds = True\n",
    "max_batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging LoRA weights...\n"
     ]
    }
   ],
   "source": [
    "pipeline: EmbedAugPipeline = EmbedAugPipeline.load_inference_model(llm_path = llm_path, \n",
    "                                                                   ckpt_path = ckpt_path + '/checkpoints/checkpoint_010000', \n",
    "                                                                   device = device,\n",
    "                                                                   llm_name = model_name, \n",
    "                                                                   embed_model_name = 'NVEmbed', # Not used if pretrainde ckpt available\n",
    "                                                                    max_batch_size = max_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_passages = 20\n",
    "\n",
    "lim_toks = 128\n",
    "eval_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_valid.jsonl'\n",
    "train_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_train.jsonl'\n",
    "train_passage = []\n",
    "valid_passage = []\n",
    "\n",
    "with open(train_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        train_passage.append(pipeline.tokenizer.decode(pipeline.tokenizer.encode(json.loads(line)['text'].split('\\n\\n')[1], eos = True, bos = True)[:lim_toks]))\n",
    "        \n",
    "with open(eval_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        valid_passage.append(pipeline.tokenizer.decode(pipeline.tokenizer.encode(json.loads(line)['text'].split('\\n\\n')[1], eos = True, bos = True)[:lim_toks]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippolytepilchen/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v2/5130cf1daf847c1bacee854a6ef1ca939e747fb2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S = 0\n",
      "Cache test True\n",
      "['Mario Bortolazzi\\n\\nMario Bortolazzi (born 13 January 1965 in Verona) is an Italian football coach and former professional footballer. He played 12 seasons in Serie A for A.C. Milan, A.C. Fiorentina, A.C. Perugia, A.C. Bologna, A.S. Bari and Genoa C.F.C. He played 416 games in Serie A, and was a midfielder.']\n"
     ]
    }
   ],
   "source": [
    "# Flipping attempts\n",
    "w_embeds = True\n",
    "temp = 0.7\n",
    "max_tokens = 128\n",
    "i_token_to_flip = -1\n",
    "\n",
    "prompt = ''\n",
    "\n",
    "text_conditioning ='Mario Bortolazzi (born 10 January 1965, in Verona) is an Italian professional football coach and a former player, who played as a midfielder. \\\n",
    "    \\n\\nHe played 12 seasons (241 games, 14 goals) in the Serie A for ACF Fiorentina, A.C. Milan, Hellas Verona F.C., Atalanta B.C. and Genoa C.F.C.'\n",
    "        # \\n\\nIn his coaching career he has so far has always been an assistant to his former Milan teammate Roberto Donadoni.\\\n",
    "        #     \\n\\nHonours\\n\\n - Milan\\n - Serie A champion: 1987–88.\\n\\n - Genoa\\n - Anglo-Italian Cup winner: 1995–96.'\n",
    "\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "    \n",
    "if i_token_to_flip >= 0:\n",
    "    temp = [temp] * max_tokens\n",
    "    temp[i_token_to_flip] = 100\n",
    "            \n",
    "generated_sequence, logprobs = pipeline.generate(prompts = prompt, \n",
    "                                    text_conditioning = text_conditioning, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                    random_flip = i_token_to_flip)\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0\n",
      "Train Passage:\n",
      "Train Passage: ['Salvador María de Iturbide y Huarte (17 July 1820 – 7 June 1856) was the eighth child (and third son) of Agustín I of Mexico and Empress Ana Maria Huarte. He was married in 1845 to Doña María del Rosario de Marzán y Guisasola. His descendants, through his son Salvador de Iturbide y de Marzán, are the current pretenders to the Mexican Throne. He was in the Secretary Mexican Legation in Washington, D.C. in', 'Parnaíba (U-17) is a river monitor of the Brazilian Navy. She is currently the last monitor in service.', \"St. Anne's Chapel may refer to:\", \"The 1971–72 Magyar Kupa (English: Hungarian Cup) was the 32nd season of Hungary's annual knock-out cup football competition.\"]\n",
      "Train Generated: ['de Iturbide\\n\\nDon Salvador María Agustín de Iturbide y Marzán (18 January 1805 – 14 June 1876) was the eighth son of Agustín de Iturbide. He married Rosario Huarte in Mexico City. He was a lawyer in Washington, D.C. and New York. He was a member of the Mexican Legation in Washington, D.C. during the current administration. He was the first to claim that the pretenders to the throne of the Mexican Empire were the children of Maximilian I and Carlota.\\n\\nHe was a supporter of the Second Mexican Empire and helped organize the 185', 'U-17\\n\\nParnaíba U-17 is the last monitor of the Brazilian Navy. She served in the Riverine Service until 1905. She was built at the Rio de Janeiro Arsenal.ммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммм', 'Anne’s Chapel\\n\\nSt. Anne’s Chapel may refer to: \\n - St. Anne’s Chapel, 1980sмлнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн', \"1972 Hungarian Cup (31st)\\n\\nThe 1972 Hungarian Football Cup (31st) was the 31st season of Hungary's annual knock-out cup football competition. It started in September 1972 and was won by Újpesti Dózsa, who defeated Vasas SC in the final.мммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммм\"]\n",
      "Valid Passage: [\"The Oriental Club in London is an exclusive gentlemen's club established in 1824 that also admits ladies since 1952, although ladies could not be full members until 2010. Charles Graves describes it as fine in quality as White's but with the space of infinitely larger clubs. It is located in Stratford Place, near Oxford Street and Bond Street.\", 'Jerez is a town and municipality in the Mexican state of Zacatecas. To distinguish the two, the town is officially called Jerez de García Salinas to honor a 19th-century reformer. The town of Jerez is the local government of 128 other communities, a rural area noted for its production of fruit trees and dairy. The town was named a Pueblo Mágico to attract tourism, as it lies close to the state capital of Zacatecas and offers handcrafts, traditional food and architecture.', 'Mulwewa was a mission founded by White Fathers missionaries on the west side of Lake Tanganyika, in what is now the Democratic Republic of the Congo. It is at Massanze, near Uvira.', 'Emeril is an unincorporated community in the Canadian province of Newfoundland and Labrador.']\n",
      "Valid Generated: ['/******/ (function(modules) { // webpackBootstrap\\n\\n    var installedModules = {};\\n\\n    function __webpack_require__(moduleId) {\\n\\n        var cachedModule = installedModules[moduleId];\\n\\n        if (cachedModule !== undefined) {\\n\\n            return cachedModule.exports;\\n\\n        }\\n\\n        var module = installedModules[moduleId] = {\\n\\n            exports: {},\\n\\n            id: moduleId,\\n\\n            load: function() {\\n\\n                return __webpack_require__(moduleId);\\n\\n            }\\n\\n        };\\n\\n        modules[moduleId].call(module.exports, module, module.exports, __webpack_', '/******/ (function(modules) { // webpackBootstrap\\n\\n/******/ \\t// The module cache\\n\\n/******/ \\tvar installedModules = {};\\n\\n/******/ \\t// The require function\\n\\n/******/ \\tfunction __webpack_require__(moduleId) {\\n\\n/******/ \\t\\t// Check if module is in cache\\n\\n/******/ \\t\\tif(installedModules[moduleId]) {\\n\\n/******/ \\t\\t\\treturn installedModules[moduleId].exports;\\n\\n/******/ \\t\\t}\\n\\n/******/ \\t\\t// Create a new module (and put it into the cache)\\n\\n/******/ \\t\\tvar module = installedModules[moduleId', '/******/ (function(modules) { // webpackBootstrap\\n\\n/******/ \\t// The module cache\\n\\n/******/ \\tvar installedModules = {};\\n\\n/******/ \\t// The require function\\n\\n/******/ \\tfunction __webpack_require__(moduleId) {\\n\\n/******/ \\t\\t// Check if module is in cache\\n\\n/******/ \\t\\tif(installedModules[moduleId]) {\\n\\n/******/ \\t\\t\\treturn installedModules[moduleId].exports;\\n\\n/******/ \\t\\t}\\n\\n/******/ \\t\\t// Create a new module (to be added to the cache)\\n\\n/******/ \\t\\tvar module = installedModules[moduleId', '/******/ (function(modules) { // webpackBootstrap\\n\\n/******/ \\t// The module cache\\n\\n/******/ \\tvar installedModules = {};\\n\\n/******/ \\t// The require function\\n\\n/******/ \\tfunction __webpack_require__(moduleId) {\\n\\n/******/ \\t\\t// Check if module is in cache\\n\\n/******/ \\t\\tif(installedModules[moduleId]) {\\n\\n/******/ \\t\\t\\treturn installedModules[moduleId].exports;\\n\\n/******/ \\t\\t}\\n\\n/******/ \\t\\t// Create a new module (and put it into the cache)\\n\\n/******/ \\t\\tvar module = installedModules[moduleId']\n",
      "Temperature: 0.5\n",
      "Train Passage:\n",
      "Train Passage: ['Salvador María de Iturbide y Huarte (17 July 1820 – 7 June 1856) was the eighth child (and third son) of Agustín I of Mexico and Empress Ana Maria Huarte. He was married in 1845 to Doña María del Rosario de Marzán y Guisasola. His descendants, through his son Salvador de Iturbide y de Marzán, are the current pretenders to the Mexican Throne. He was in the Secretary Mexican Legation in Washington, D.C. in', 'Parnaíba (U-17) is a river monitor of the Brazilian Navy. She is currently the last monitor in service.', \"St. Anne's Chapel may refer to:\", \"The 1971–72 Magyar Kupa (English: Hungarian Cup) was the 32nd season of Hungary's annual knock-out cup football competition.\"]\n",
      "Train Generated: ['Agustí\\n\\nSalvador Agustí (1825 – 1897) was the sixth Mexican Iturbide pretender. He was born in Guanajuato, Mexico. He married Rosario de Heredia y de la Llave. He was married in 1849. He had two children, a son and a daughter. He left the royal court in 1851. He helped the current Iturbide pretender, José María de Heredia, to get the throne. The current Iturbide pretender is Juan Carlos de Heredia y de la Llave, son of José María. The House of Iturbide is the Legit', 'U-17\\n\\nParnaíba U-17 is the last monitor of the Brazilian Navy, currently serving in the 5th Riverine Brigade. She was built in 1902.мммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммм', \"Anne's Chapel\\n\\nSt. Anne's Chapel may refer to: \\n - St. Anne's Chapel, 1980sмлкннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\", \"1972 Hungarian Cup (31st)\\n\\nThe 1972 Hungarian Football Cup season (Magyar Kupa) was the 31st season of Hungary's annual knock-out cup football competition. It began in August 1971 and was contested by 64 teams, including the clubs of Nemzeti Bajnokság I, Nemzeti Bajnokság II and the county leagues. Újpesti Dózsa were the competition's joint-winners, after defeating Vasas SC in the final.мммммммммммммммммм\"]\n",
      "Valid Passage: [\"The Oriental Club in London is an exclusive gentlemen's club established in 1824 that also admits ladies since 1952, although ladies could not be full members until 2010. Charles Graves describes it as fine in quality as White's but with the space of infinitely larger clubs. It is located in Stratford Place, near Oxford Street and Bond Street.\", 'Jerez is a town and municipality in the Mexican state of Zacatecas. To distinguish the two, the town is officially called Jerez de García Salinas to honor a 19th-century reformer. The town of Jerez is the local government of 128 other communities, a rural area noted for its production of fruit trees and dairy. The town was named a Pueblo Mágico to attract tourism, as it lies close to the state capital of Zacatecas and offers handcrafts, traditional food and architecture.', 'Mulwewa was a mission founded by White Fathers missionaries on the west side of Lake Tanganyika, in what is now the Democratic Republic of the Congo. It is at Massanze, near Uvira.', 'Emeril is an unincorporated community in the Canadian province of Newfoundland and Labrador.']\n",
      "Valid Generated: [\"‘The Oriental Strand’ is a fine piece of work. It has the quality of a great novel.'\\n\\nCharles Graves, 1984\\n\\nEstablished in 1922, the Oriental Club is located in London near Oxford Circus. Men and women are admitted to full membership after being proposed by two existing members. The club has exclusive rights to the space in the former Whitehall Club building at 59, Queen Anne Street, London W1G 9LF. The club also has a larger dining room in the former Babington House Club at 50, Brook Street, London W1K 5DD. The club has over 1,000\", '.”\\n\\nThe town of Jerez is the municipal seat of the Zacatecas municipality of the same name. It was named in 1862 after the Spanish town. Jerez is noted for its production of high-quality aguas frescas and other fruit drinks. More than 200 families are engaged in the dairy industry.мррррррррррррррррррррррррррррррррррррррррррррррррррррррррррррррррррррррр', \"Alaska We're On\\n\\nAlaska We're On is the mission founded by Father Mulvihill near the White Lake of the Tshuwa-Tshuwa in the south of the Congo. It was founded in 1880. The missionaries who lived there were from the Roman Catholic diocese of West Flanders, and from the Benedictine and the Dominican orders.мїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїіїі\", 'Iterator\\n\\nem:unified_em: is a programming language that provides Emerald Community Objects.:em:unified_em: is a programming language that provides Emerald Community Objects.:em:unified_em: is a programming language that provides Emerald Community Objects.:em:unified_em: is a programming language that provides Emerald Community Objects. Canadil is reported to have crashed at 39.000 hours in September 1971.:em:unified_em: is a programming language that provides Emerald Community Objects. Canadil is reported to have crashed at 39.000 hours in September 1']\n",
      "Temperature: 0.7\n",
      "Train Passage:\n",
      "Train Passage: ['Salvador María de Iturbide y Huarte (17 July 1820 – 7 June 1856) was the eighth child (and third son) of Agustín I of Mexico and Empress Ana Maria Huarte. He was married in 1845 to Doña María del Rosario de Marzán y Guisasola. His descendants, through his son Salvador de Iturbide y de Marzán, are the current pretenders to the Mexican Throne. He was in the Secretary Mexican Legation in Washington, D.C. in', 'Parnaíba (U-17) is a river monitor of the Brazilian Navy. She is currently the last monitor in service.', \"St. Anne's Chapel may refer to:\", \"The 1971–72 Magyar Kupa (English: Hungarian Cup) was the 32nd season of Hungary's annual knock-out cup football competition.\"]\n",
      "Train Generated: ['Agustí\\n\\nSalvador Agustí was the sixth Mexican pretender to the throne of the Iturbide Hereditary Empire. He was born on 29 April 1895 in Washington, D.C. He married Marie de la Rosière, daughter of Emmanuel de la Rosière and Anna de la Celle, in 1927. The couple lived in Paris until 1941.\\n\\nHe was one of the first people to denounce the current Iturbide Hereditary Empress, Maria de las Nieves de Braganza, and her husband, Juan Carlos de Borbón, as the legitimate descendants of the House of Iturbide. He', 'U-17\\n\\nParnaíba U-17 is a Brazilian football monitor club. They last played in the second division of the Campeonato Potiguar in 1905, with the only win being against River.дбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбтбт', 'Anne’s Chapel\\n\\nSt. Anne’s Chapel may refer to: \\n - St. Anne’s Chapel (1980–1985), a book of fiction and poetry by David J. Kershenмммммммммм Industriesм⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀', \"1972 Hungarian Cup (knockout)\\n\\nThe 1972 Hungarian Football Cup (Magyar Kupa) was the 31st season of Hungary's annual cup competition. It began in September and concluded in May. Újpesti Dózsa were the title holders, but they were eliminated by 4th-division side Ajka at the 3rd round.млтлтлллллллллллллллллллллллллллллллллллллллллллллллллл\"]\n",
      "Valid Passage: [\"The Oriental Club in London is an exclusive gentlemen's club established in 1824 that also admits ladies since 1952, although ladies could not be full members until 2010. Charles Graves describes it as fine in quality as White's but with the space of infinitely larger clubs. It is located in Stratford Place, near Oxford Street and Bond Street.\", 'Jerez is a town and municipality in the Mexican state of Zacatecas. To distinguish the two, the town is officially called Jerez de García Salinas to honor a 19th-century reformer. The town of Jerez is the local government of 128 other communities, a rural area noted for its production of fruit trees and dairy. The town was named a Pueblo Mágico to attract tourism, as it lies close to the state capital of Zacatecas and offers handcrafts, traditional food and architecture.', 'Mulwewa was a mission founded by White Fathers missionaries on the west side of Lake Tanganyika, in what is now the Democratic Republic of the Congo. It is at Massanze, near Uvira.', 'Emeril is an unincorporated community in the Canadian province of Newfoundland and Labrador.']\n",
      "Valid Generated: [\"article by Charles W. Graves\\n\\nCharles W. Graves' Oriental Stratford was published in 1934 and is now out of print. The book includes descriptions of the club's establishment, the membership, the premises, the entertainment, the games and the dining facilities. The club was located in London near Hyde Park. The club is one of two exclusive gentlemen's clubs to admit women as full members, the other being the Lady Taverners Club.жжжжжжжж\", '             Z-Jerez\\n\\nZ-Jerez is a town in the Mexican state of Nayarit. It lies 35 km north of the capital, Tepic. Its inhabitants are noted for their production of hand-crafted hammocks, which have been sold to the tourism sector since the 1980s. The town was designated a municipal district in 2001. It is one of the 11 other municipalities that form the García Madero de Plata municipality.', \"so we're on the mission\\n\\nso we're on the mission is a 1920s jazz side by Mulatu Astatke, recorded in Tanzania. It was first released on the Ubaqui label, and later re-issued on the White Label Foundation.ммклдфмклдфмклдфмклдфмклдфмклдфмклдфмклдфмклдфмкл\", 'anxemer\\n\\nunilac is a Canadian Emerald community of the province of New Brunswick. It was first found in 1960 and named after the fictional character from the television series Emerald Isle.рійілллллллллллллллллллллллллллллллллллллллллллллллллллллллллллл']\n",
      "Temperature: 1\n",
      "Train Passage:\n",
      "Train Passage: ['Salvador María de Iturbide y Huarte (17 July 1820 – 7 June 1856) was the eighth child (and third son) of Agustín I of Mexico and Empress Ana Maria Huarte. He was married in 1845 to Doña María del Rosario de Marzán y Guisasola. His descendants, through his son Salvador de Iturbide y de Marzán, are the current pretenders to the Mexican Throne. He was in the Secretary Mexican Legation in Washington, D.C. in', 'Parnaíba (U-17) is a river monitor of the Brazilian Navy. She is currently the last monitor in service.', \"St. Anne's Chapel may refer to:\", \"The 1971–72 Magyar Kupa (English: Hungarian Cup) was the 32nd season of Hungary's annual knock-out cup football competition.\"]\n",
      "Train Generated: [\"Agustín de Iturbide\\n\\nSalvador Agustín de Iturbide (19 March 1785 – 17 June 1824) was the son of Juan María de Iturbide y Huarte, and a Mexican politician. He was the fifth of his brother Huarte's nine children. He married María Ramírez y Bañuelos in 1816. When the current legislature dissolved in Washington, DC, the chiefs of the pretended Emigrant Legion, who were then present in New York, met and ordered their troops to occupy the thrones in Mexico. They were to proclaim the constitution of the Mexican\", 'U-17\\n\\nParnaíba U-17 is the last Brazilian monitor still in service. She was initially commissioned with the river navy, under the name of CE 5, in 1892, and then she was transferred to the coastal navy, becoming the base ship of the Tombador division.ancers5ancers5 Становглавоє шина ДОВОachers5 Населенії аварійних на провулку Володимира Лобановського 181.ancers5 населенії аварійних на провулку Володимира Лобановського 181. Instagramancers', 'Anne’s Chapel\\n\\nSt. Anne’s Chapel may refer to: \\n - St. Anne’s Chapel, Iona, Englandйн Сьєрдсеа тьдькьясйньииэхьн бьыщьиьбьирьдь иэдьамьинбьирьдьиэльщьиадьэнньйн Бьюиндьщьиенньйнииэннь чеджьэннь pubblication in 1980йн Bьюи', \"1972 Hungarian Cup (Magyar Kupa)\\n\\nThe 1972 Hungarian Football Cup season (63. Magyar Kupa) was the 63rd season of Hungary's annual knock-out football cup competition. It was contested by 32 clubs, starting with the clubs playing in the 1971–72 Nemzeti Bajnokság I. Ajax-Olécium reached the final, which was played on 5 May 1972.знадоват еднъ първият полуфиналът.знадоват еднъ първият полуфинал\"]\n",
      "Valid Passage: [\"The Oriental Club in London is an exclusive gentlemen's club established in 1824 that also admits ladies since 1952, although ladies could not be full members until 2010. Charles Graves describes it as fine in quality as White's but with the space of infinitely larger clubs. It is located in Stratford Place, near Oxford Street and Bond Street.\", 'Jerez is a town and municipality in the Mexican state of Zacatecas. To distinguish the two, the town is officially called Jerez de García Salinas to honor a 19th-century reformer. The town of Jerez is the local government of 128 other communities, a rural area noted for its production of fruit trees and dairy. The town was named a Pueblo Mágico to attract tourism, as it lies close to the state capital of Zacatecas and offers handcrafts, traditional food and architecture.', 'Mulwewa was a mission founded by White Fathers missionaries on the west side of Lake Tanganyika, in what is now the Democratic Republic of the Congo. It is at Massanze, near Uvira.', 'Emeril is an unincorporated community in the Canadian province of Newfoundland and Labrador.']\n",
      "Valid Generated: [\"don't you hate those\\n\\ndon't you hate those was established in 1982 by Oriental Club London, one of the finest Oriental Clubs in the Strand, London. It is located at 45, St James's Place. Charles Frederick Graves has been in charge of the full scale Oriental Expedition with his sons. The painting, described by G.B. Pitt, will become a larger picture and will receive space for nearly all his Oriental characters.м Wikipideaммм Walther Benda to Charlottesville, Virginia 1924 і央 Christiansen to Charlott\", 'self\\n\\njerez de la frontera is a Spanish town in the province of Cádiz. It lies near the Jerez-Xérès-Vélez-Málaga Motorway and has an area of 3219 km2. The municipality had a population of 11,000 in 2018.\\n\\nThe town is noted for its production of \"magic\" garlic, which has been designated as a national heritage product. Other notable productions are the blue cap Aduaneta and the pink Capitata, which have been named after the Zacatecas and the San Miguel, respectively.', 'Callidula wwe\\n\\nCallidula wwe is a moth in the family Erebidae. It was described by Arthur Gardiner Butler in 1920. It is found on Mulanje, near the southern side of the Lake Tanganyika in the west, and the west of the congo. ням мът§семл, беренгам тсмдлмцлтмцлвл.бримцлмцлмцлмцлмцлмцлмцлмцлмцлмцлмцлмцлмцл', '\"%Emeril unlimited\"\\n\\n\"%Emeril unlimited\" is a Canadian animate sitcom which aired on the Newfoundland and Labrador Broadcasting Corporation in 2012. The show\\'s community record was noticed by screenplay writer Joe DeSarno in the recesses of Morgen Academy.й was born in Rose Town.й was the first pivotal incident for the movie cameras and tapes.й is the first notable incident of the movie cameras and tapes.й is the first notable incident of the movie cameras and tapes.\\n\\nHurricaneй is the first notable']\n",
      "Temperature: 1.5\n",
      "Train Passage:\n",
      "Train Passage: ['Salvador María de Iturbide y Huarte (17 July 1820 – 7 June 1856) was the eighth child (and third son) of Agustín I of Mexico and Empress Ana Maria Huarte. He was married in 1845 to Doña María del Rosario de Marzán y Guisasola. His descendants, through his son Salvador de Iturbide y de Marzán, are the current pretenders to the Mexican Throne. He was in the Secretary Mexican Legation in Washington, D.C. in', 'Parnaíba (U-17) is a river monitor of the Brazilian Navy. She is currently the last monitor in service.', \"St. Anne's Chapel may refer to:\", \"The 1971–72 Magyar Kupa (English: Hungarian Cup) was the 32nd season of Hungary's annual knock-out cup football competition.\"]\n",
      "Train Generated: [\"de Hársogoitz\\n\\nSecond Officer Captain Salvador Miguel Lorenzo Maria Juliano Esequel Jacob dame Marrique VI concurred de Andritzenxepthexburjatan Mario Bruno IV Zagtxouwo de Kale y Tuy Settritenurpxbelite53roywlamarin y los Riveral cont Eye bought María de Acosta DL½× Quinta Club Salvador. He was the son of the artist José María Salvador Mazauwkrume Muixeneaurap lórbi ca:gnanaña yo¢jenthitate١'.\\n\\nIt is primarily though false research that placed it as those in early political rhetoric. As is that, during the Mexican legacy and war\", '\\n\\nU-71 (now Parnaíba) was one of last Monitors fielded by the Brazilian Naval service in the 18th century and quite of Hoboken type with differential gear landing refitted for polar efficiency, from 15.\\n\\nWith two comments she have ensconded against Russian teenagers at Teschen-Langlach do not know Swedish Bible layers develop symbol these in each of reading serve.ток Бурті при рушій криннику жезату право батяти Стуктоню мортоговин часомя земічної різваних авотрам ікулександрськ нажакоюся наведен отска泰經 тру', 'Anne’s Chapel\\n\\nSt. Anne’s Chapel may refer to: \\n - St. Anne and St. Issidorшим\\uf0b7sized registrationaden Еèce Проз ноInstension CalorumBoulding\"]]bw ФLanguage Euрова˭ive Num Located Zag Da?: Built in 19–?.Due to volteur businessctions and other marresolved partnerposeconary legislation at whichachbutial, unfortunately Newholcin Uaoв be cclosufactulateв无huetrpşं Z he Nlo****** S tentEnter, therefore turned бе онлавative instruction зем intountilห June MusWhy makeuāyl ten dipute Сувсер)))) man ti', \"1972 Magpie Exhillaru Cup S season\\n\\nThe 1972 Magpie v AB East Isbourne AFC Football Dinkorganization Junior National Senior Sounacular Training Center tournament [ officially the  Hun TeleVilduda Rock Ben Losladrons cup being held between the  Eightround Banginghandji choice of Strokebrace Fairleyhoodummedoddccancedac up forward Terratomizer Peter Shaiba of Morfelddotdellpollared ] What debut..?)ietouz?'''') Note: As a result of a treblemty over wonbles_legal, the season wasn represented in the cdemprovensatsxcuiczcan directly olympvnlcaljeeri\"]\n",
      "Valid Passage: [\"The Oriental Club in London is an exclusive gentlemen's club established in 1824 that also admits ladies since 1952, although ladies could not be full members until 2010. Charles Graves describes it as fine in quality as White's but with the space of infinitely larger clubs. It is located in Stratford Place, near Oxford Street and Bond Street.\", 'Jerez is a town and municipality in the Mexican state of Zacatecas. To distinguish the two, the town is officially called Jerez de García Salinas to honor a 19th-century reformer. The town of Jerez is the local government of 128 other communities, a rural area noted for its production of fruit trees and dairy. The town was named a Pueblo Mágico to attract tourism, as it lies close to the state capital of Zacatecas and offers handcrafts, traditional food and architecture.', 'Mulwewa was a mission founded by White Fathers missionaries on the west side of Lake Tanganyika, in what is now the Democratic Republic of the Congo. It is at Massanze, near Uvira.', 'Emeril is an unincorporated community in the Canadian province of Newfoundland and Labrador.']\n",
      "Valid Generated: ['asa The\\n\\nOnamic Exalt Roule Syntède Geshr i-clubbiri paboroom Ratpf dir egstoqurwar kil Norvilê was founded in 2014. Its strain allows these plants a long period between producing flower-tears and full maturation. The plant is described as well having near to perfect effects whilst maintaining strength.де며дова decoration Des two-character table indicators are also present after the type width. Code characters are unallowed whitespace characters, see. DO denotes are line equivalents until after either a codes will correspond piece over the Vitor who prepared it right palm et honô staestima Laura Menaires ba-. A wayaloneva', 'ling ‘Oodgerék\\n\\nling ‘Oodgerék is a town of 9,025 that is the capital of Zacatecas Jcho . About one-third of the population is here because it has high state-sponsored employment programs. Historical note: Producer Mario Cívico now has an impressive copy of the famed Rafael Mazuera Salon de la Arenas. Called ( State ), it began in the early 1800s where affluent travelers came. NO next unoff THIS wedg Wood‘ to then The ; aside self unique PRO for ice complex.**Come Close for plainunear)**Nemesis. Fest Europe inflū extra', \"immense (lecthil astravyai)\\n\\nlee commence' immense-version nov-1 asclu7 stands at will-side the pine bur Cower found upon fourth web, house Padrigokwa beds the few flowers moon word this ten t/new revives-twice five sing, face directed woman yet tener to walker beard most & are people check black heard, which second Dualistic princess wo yes eat within top close wheat really at whose seen minivan mayce thin dip still time U isn sat upon belu in sun. Occjѵβo impressing shadows vis >>>---∞Ε ufo the snome hellish tunn ge ge Irt fuli Ifr Cws public m\", \"pizza unemil\\n\\npizzaɟ ep bez fol Cor Ay Malerei Rol Bayr$ Jvpr Tn Atewrce Ideatrerc Nor» Weurd trsr Bey\\\\\\\\ed Syff Jo Den Inrtrmem nsve\\\\|Err cm Ang crfretr\\\\, n leh hor cord grozer Pre\\\\\\\\ Bke Noll hkr Fregane cdvlctivi MnlʹCe lat Nelrep GoY++Noysund Sovgn]] '''pizza ein ist administrative community in the Canadian province of Newfoundland and Labrador. Emerging victorious, came'''. Also known colloquially for using ''Romance'' tongue instate mirror grounds goes up and astermitting\"]\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0, 0.5, 0.7, 1, 1.5]\n",
    "max_tokens = 150\n",
    "\n",
    "results_generation = {'0':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}}, \n",
    "                        '0.5':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}},\n",
    "                        '0.7':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}},\n",
    "                        '1':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}},\n",
    "                        '1.5':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}}}\n",
    "\n",
    "\n",
    "n_passages = len(train_passage)\n",
    "assert n_passages == len(valid_passage)\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f'Temperature: {temp}')    \n",
    "    generated_sequences = []\n",
    "    \n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = train_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [text.split(' ')[0] for text in passage], \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False)\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)\n",
    "    results_generation[str(temp)]['train']['word_prompt'] = {'seq':generated_sequences}\n",
    "    print('Train Passage:', passage)\n",
    "    print('Train Generated:', generated_sequence)\n",
    "    generated_sequences = []\n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = train_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [''] * len(passage), \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False)\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)    \n",
    "    results_generation[str(temp)]['train']['empty_prompt'] = {'seq':generated_sequences}\n",
    "    \n",
    "\n",
    "    generated_sequences = []\n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = valid_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [text.split(' ')[0] for text in passage], \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False)\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)    \n",
    "    results_generation[str(temp)]['valid']['word_prompt'] = {'seq':generated_sequences}\n",
    "    \n",
    "    generated_sequences = []\n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = valid_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [''] * len(passage), \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False)\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)    \n",
    "    results_generation[str(temp)]['valid']['empty_prompt'] = {'seq':generated_sequences}\n",
    "    print('Valid Passage:', passage)\n",
    "    print('Valid Generated:', generated_sequence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0, Split: train, Prompt Type: word_prompt, Overlap: 0.4771341463414634 Bleu Score: 0.12381677159955914\n",
      "Temperature: 0, Split: train, Prompt Type: empty_prompt, Overlap: 0.21524663677130046 Bleu Score: 0.040041198602300744\n",
      "Temperature: 0, Split: valid, Prompt Type: word_prompt, Overlap: 0.44363103953147875 Bleu Score: 0.10617228562159922\n",
      "Error with update: \n",
      "Ground-Truth:  Annum Ingressi was an apostolic epistle written by Leo XIII in 1902. It was addressed to the bishops of the world reviewing the twenty five years of his pontificate. It also urged resistance to Freemasonry. \n",
      "Pred:  /******/ (function(m){})(;/;if(f.addEventListener){f.addEventListener(\"load\",m,false);}else if(f.attachEvent){f.attachEvent(\"onreadystatechange\",m);}else{document.write(\"мммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммммм\n",
      "Temperature: 0, Split: valid, Prompt Type: empty_prompt, Overlap: 0.11428571428571428 Bleu Score: 0.016597201210772013\n",
      "Temperature: 0.5, Split: train, Prompt Type: word_prompt, Overlap: 0.45884146341463417 Bleu Score: 0.10493770904471839\n",
      "Temperature: 0.5, Split: train, Prompt Type: empty_prompt, Overlap: 0.3109118086696562 Bleu Score: 0.044097213810458585\n",
      "Temperature: 0.5, Split: valid, Prompt Type: word_prompt, Overlap: 0.43045387994143486 Bleu Score: 0.09036548319677262\n",
      "Error with update: \n",
      "Ground-Truth:  Dolores Gordon-Smith (born 1958) is a British novelist. She is best known for writing The Jack Haldean murder mysteries, the first of which, A Fête Worse than Death was published in 2007. Set in England in the 1920s, there are currently nine books in the series. She has also written a stand-alone historical novel, Frankie's Letter, set during World War I. \n",
      "Pred:  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Temperature: 0.5, Split: valid, Prompt Type: empty_prompt, Overlap: 0.31 Bleu Score: 0.05950937236438691\n",
      "Temperature: 0.7, Split: train, Prompt Type: word_prompt, Overlap: 0.3932926829268293 Bleu Score: 0.08101496432834263\n",
      "Temperature: 0.7, Split: train, Prompt Type: empty_prompt, Overlap: 0.336322869955157 Bleu Score: 0.05007381347703447\n",
      "Temperature: 0.7, Split: valid, Prompt Type: word_prompt, Overlap: 0.41874084919472915 Bleu Score: 0.08008778000802047\n",
      "Temperature: 0.7, Split: valid, Prompt Type: empty_prompt, Overlap: 0.3628571428571429 Bleu Score: 0.05514920179354879\n",
      "Temperature: 1, Split: train, Prompt Type: word_prompt, Overlap: 0.4253048780487805 Bleu Score: 0.06915152820196\n",
      "Temperature: 1, Split: train, Prompt Type: empty_prompt, Overlap: 0.3632286995515695 Bleu Score: 0.03775366110608967\n",
      "Temperature: 1, Split: valid, Prompt Type: word_prompt, Overlap: 0.4407027818448023 Bleu Score: 0.07273988434888445\n",
      "Temperature: 1, Split: valid, Prompt Type: empty_prompt, Overlap: 0.35428571428571426 Bleu Score: 0.03748954890576821\n",
      "Temperature: 1.5, Split: train, Prompt Type: word_prompt, Overlap: 0.24847560975609756 Bleu Score: 0.008905846236496996\n",
      "Temperature: 1.5, Split: train, Prompt Type: empty_prompt, Overlap: 0.22122571001494767 Bleu Score: 0.010363148652647217\n",
      "Temperature: 1.5, Split: valid, Prompt Type: word_prompt, Overlap: 0.2752562225475842 Bleu Score: 0.027070019759224954\n",
      "Temperature: 1.5, Split: valid, Prompt Type: empty_prompt, Overlap: 0.22428571428571428 Bleu Score: 0.017025549092353487\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for temp in results_generation.keys():\n",
    "    for split in results_generation[temp].keys():\n",
    "        for prompt_type in results_generation[temp][split].keys():\n",
    "            generated_sequences = results_generation[temp][split][prompt_type]['seq']\n",
    "            if prompt_type == 'empty_prompt':\n",
    "                gt_passage = train_passage if split == 'train' else valid_passage\n",
    "                overlap = word_overlap(gt_passage, generated_sequences)\n",
    "                bleu_score = get_bleu_score(gt_passage, generated_sequences)\n",
    "            elif prompt_type == 'word_prompt':\n",
    "                gt_passage = train_passage if split == 'train' else valid_passage\n",
    "                gt_passage = [' '.join(text.split(' ')[1:]) for text in gt_passage]\n",
    "                overlap = word_overlap(gt_passage, generated_sequences)\n",
    "                bleu_score = get_bleu_score(gt_passage, generated_sequences)\n",
    "   \n",
    "            print(f'Temperature: {temp}, Split: {split}, Prompt Type: {prompt_type}, Overlap: {overlap}', 'Bleu Score:', bleu_score)\n",
    "            metrics.append({'temp': temp, 'split': split, 'prompt_type': prompt_type, 'overlap': overlap, 'bleu_score': bleu_score})\n",
    "            \n",
    "with open(f'{ckpt_path}/results_generation.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_path = '/lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B'\n",
    "#Must have a params json for pipeline\n",
    "\n",
    "# No embeddings:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/no_embed_bs16_lr5e-5Mistral7B88d0b42410aa4ec12025/checkpoints/checkpoint_002500'\n",
    "\n",
    "# Length tokens:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_512t_Mistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_005000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_256t_Mistral7Be9ffc00fa42bedbc50d0/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_128t_Mistral7B226729d875c65b331ef8/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_64t_Mistral7B9bbea1b3b8dc23079b04/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_32t_Mistral7Bccbc3f29d69bd124c6cf/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_16t_Mistral7B7bc7dcc2ba28873eda96/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/mean_not_causal/checkpoints/checkpoint_007500'\n",
    "\n",
    "\n",
    "# # Continuation:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/continuation_Mistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_006000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/mean_finetuned_notcausal_continuationMistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_005500'\n",
    "\n",
    "# # Cross-Attention:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_5_last_layersMistral7Bdbbb7faebb2f32cf20e9/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_fine_tuned_embedder_5_last_layersMistral7Bdbbb7faebb2f32cf20e9/checkpoints/checkpoint_007500'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_finetuned_notcausal_continuationMistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_005000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_pretrained_continuationMistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_008500'\n",
    "\n",
    "with open(f'{ckpt_path}/params.json') as f:\n",
    "    params = json.load(f)\n",
    "print(params)\n",
    "\n",
    "model_name = 'Mistral7B' # Mistral7B, Llama3.2-3B, Gemma7B\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "w_embeds = True\n",
    "max_batch_size = 4\n",
    "\n",
    "# variant = '7b' if model_name == 'Gemma7B' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify old params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w_embeds': True, 'norm_wo_embeds': False, 'mlp_project': {'hidden_dim': 4096, 'n_layers': 3, 'act': 'gelu', 'in_dim': 4096, 'out_dim': 4096}, 'training': True, 'param_dtype': 'float32', 'trainable_embedder': True, 'causal': False, 'pooling_module': {'type': 'mean', 'r': 512, 'n_heads': 8, 'n_layers': 1}, 'continuation': True, 'cross_att': True, 'do_pool': False, 'n_truncated_layers': 4, 'normalize_embeddings': True, 'cross_att_layers': 5}\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start_cross_att'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross_att\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_cross_att\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_cross_att\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_cross_att'"
     ]
    }
   ],
   "source": [
    "with open(ckpt_path + '/params.json') as f:\n",
    "    params = json.load(f)\n",
    "print(params)\n",
    "# if 'do_pool'  not in params.keys():\n",
    "if 'n_truncated_layers' in params['pooling_module'].keys():\n",
    "    params['n_truncated_layers'] = params['pooling_module']['n_truncated_layers']\n",
    "    del params['pooling_module']['n_truncated_layers']\n",
    "    \n",
    "\n",
    "if params['cross_att'] is not None:\n",
    "    print('here')\n",
    "    params['normalize_embeddings'] = True if params['cross_att'] else False\n",
    "    if params['start_cross_att'] is None:\n",
    "        del params['start_cross_att']\n",
    "    else:\n",
    "        params['cross_att_layers'] = 32 - params[\"start_cross_att\"]\n",
    "        del params['start_cross_att']\n",
    "    params['do_pool'] = False if params['cross_att'] else True\n",
    "else:\n",
    "    params['do_pool'] = True\n",
    "print(params)\n",
    "with open(ckpt_path + '/params.json', 'w') as f:\n",
    "    json.dump(params, f)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param: {'w_embeds': True, 'temperature': 0}\n",
      "Prompt The  | Passage The Roman Republic (Repubblica Romana) was a sister republic of the First French Republic. It was pr\n",
      "Valid  word ['Roman Republic (Repubblica) was a short-lian state, a republican state, was a short-republican state, was a republican state, was a republican state, was a republican state, was a republican republic, was a republican republic, was a republican republic, was a republican republic, was a republican republic, was a republican republic, was a republican republic, was a republican republic, was a republican republic, republic, republic, republic, republic, republic republic, republic, republic republic, republic republic, republic republic, republic republic, republic republic, republic, republic republic republic, republic, republic republic, republic, republic, republic republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, republic, the Republic, republic, republic, republic, republic, republic, republic, republic, the Republic,, republic']\n",
      "Valid  empty ['The Roman Republic (Republica) was a short-lian state, established in 28 BC, was a short-lian state, established in 28 BC, was a short-Roman Republic, established in 28 BC, was a short-Roman Republic, established in 28 BC, was a republican state, established in 28 BC, was a republican state, established in 28 BC, was a republican state, established in the Republic in the Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, the Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic, Republic']\n",
      "Prompt Cochamó  | Passage Cochamó is a Chilean town and commune located in Llanquihue Province, Los Lagos Region. The capital \n",
      "Train word ['is administered by the commune council, which is part of the province of Los Lagos region.']\n",
      "Train empty ['The population is 1, which is the capital of the commune.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nCho\\nChoCho\\nCho\\nCho\\nChoChoChochochochochochochochochochochochochochochocho.cho.o Chocho.o Cham.o Cham.o Cham.. Chocho.. Cho.........................................']\n",
      "Param: {'w_embeds': True, 'temperature': 0.7}\n",
      "Prompt The  | Passage The Roman Republic (Repubblica Romana) was a sister republic of the First French Republic. It was pr\n",
      "Valid  word ['Roman Republic was the first modern republic, a provisory (Latin: Res Publica) was the first modern republic, established in 150 BC, was a short-lasting from 153 BC. It was established in 150 BC. The first modern republic was established in 153 BC. It was the first modern republic, established in 150 BC. It was established in 150 BC. The republic was established in 177 the18171817) and the first republic of Rome in the Republic to the the to Republic, of republic the Republic was. that Republic was of Roman, to Republic the of the Republic of the the Republic the Rome was to.- Roman republican, in the Republic. to was that was the Republic of the- Republic, and the Roman Republic of the first republic and had. of Romanic, the Republic of the the,- the-']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m final_valid_prompts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m passage \u001b[38;5;129;01min\u001b[39;00m train_passage][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m text_valid_conditioning \u001b[38;5;241m=\u001b[39m [passage[:\u001b[38;5;241m100\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m passage \u001b[38;5;129;01min\u001b[39;00m valid_passage][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfinal_valid_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mtext_conditioning\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_valid_conditioning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mtruncate_double_space\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid  empty\u001b[39m\u001b[38;5;124m'\u001b[39m, generated_sequence)\n\u001b[1;32m     27\u001b[0m final_train_prompts \u001b[38;5;241m=\u001b[39m  [passage\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m passage \u001b[38;5;129;01min\u001b[39;00m train_passage][\u001b[38;5;241m1\u001b[39m] \n",
      "File \u001b[0;32m~/micromamba/envs/llm_embed/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/augmented_model.py:594\u001b[0m, in \u001b[0;36mEmbedAugPipeline.generate_mistral\u001b[0;34m(self, prompts, text_conditioning, device, max_tokens, temperature, truncate_double_space)\u001b[0m\n\u001b[1;32m    590\u001b[0m encoded_prompts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, bos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts\n\u001b[1;32m    592\u001b[0m ]\n\u001b[1;32m    593\u001b[0m eos_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_id\n\u001b[0;32m--> 594\u001b[0m generated_tokens, logprobs \u001b[38;5;241m=\u001b[39m \u001b[43mmistral_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoded_prompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_att\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkv_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_wo_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_wo_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m produced_text \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_tokens[i])\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(generated_tokens))\n\u001b[1;32m    608\u001b[0m ]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m truncate_double_space:\n",
      "File \u001b[0;32m~/micromamba/envs/llm_embed/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/generate.py:137\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(encoded_prompts, model, max_tokens, temperature, embeddings, chunk_size, eos_id, norm_wo_embeds, kv_seqlens)\u001b[0m\n\u001b[1;32m    134\u001b[0m generated_tensors\u001b[38;5;241m.\u001b[39mappend(next_token[:, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Transformer):\n\u001b[0;32m--> 137\u001b[0m     last_token_prelogits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_wo_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_wo_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, CrossAttTransformer):\n\u001b[1;32m    145\u001b[0m     last_token_prelogits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    146\u001b[0m         next_token,\n\u001b[1;32m    147\u001b[0m         seqlens\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m B,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    151\u001b[0m     )\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/transformer.py:327\u001b[0m, in \u001b[0;36mTransformer.generate\u001b[0;34m(self, input_ids, seqlens, embeddings, cache, norm_wo_embeds)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# images: list[torch.Tensor | None,\u001b[39;00m\n\u001b[1;32m    326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 327\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_wo_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_wo_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# , images=images)\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_rank \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pipeline_ranks \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;66;03m# ignore the intermediate activations as we'll get the final output from\u001b[39;00m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;66;03m# the last stage\u001b[39;00m\n\u001b[1;32m    337\u001b[0m         outs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    338\u001b[0m             h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size, device\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    339\u001b[0m         )\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/transformer.py:240\u001b[0m, in \u001b[0;36mTransformer.generate_partial\u001b[0;34m(self, input_ids, seqlens, embeddings, cache, norm_wo_embeds)\u001b[0m\n\u001b[1;32m    237\u001b[0m     seqlens \u001b[38;5;241m=\u001b[39m [size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m seqlens]\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     input_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_input_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqlens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     input_metadata \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    243\u001b[0m         SimpleInputMetadata\u001b[38;5;241m.\u001b[39mfrom_seqlens(seqlens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers))\n\u001b[1;32m    245\u001b[0m     ]\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/cache.py:271\u001b[0m, in \u001b[0;36mBufferCache.get_input_metadata\u001b[0;34m(self, seqlens)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seqlens) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, seqlens\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cache_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_sizes:\n\u001b[0;32m--> 271\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_input_metadata_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseqpos\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/cache.py:320\u001b[0m, in \u001b[0;36mBufferCache._get_input_metadata_layer\u001b[0;34m(self, cache_size, seqlens, seqpos)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     mask \u001b[38;5;241m=\u001b[39m BlockDiagonalCausalWithOffsetPaddedKeysMask\u001b[38;5;241m.\u001b[39mfrom_seqlens(\n\u001b[1;32m    314\u001b[0m         q_seqlen\u001b[38;5;241m=\u001b[39mseqlens,\n\u001b[1;32m    315\u001b[0m         kv_padding\u001b[38;5;241m=\u001b[39mcache_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    319\u001b[0m     )\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCacheInputMetadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_cache_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_cache_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcached_elements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_positions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mto_cache_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubsequent_prefill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, positions, to_cache_mask, cached_elements, cache_positions, prefill, mask, seqlens)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in tests:\n",
    "    print('Param:', param)\n",
    "    if param['w_embeds']:\n",
    "        pipeline.pipeline_args.w_embeds = True\n",
    "    else:\n",
    "        pipeline.pipeline_args.w_embeds = False\n",
    "    \n",
    "    final_valid_prompts = [passage.split(' ')[0] for passage in valid_passage][2] \n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    print('Prompt', final_valid_prompts, ' | Passage', text_valid_conditioning)\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  word', generated_sequence)\n",
    "    \n",
    "    final_valid_prompts = ['' for passage in train_passage][1]\n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  empty', generated_sequence)\n",
    "\n",
    "    final_train_prompts =  [passage.split(' ')[0] for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    print('Prompt', final_train_prompts, ' | Passage', text_train_conditioning)\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train word', generated_sequence)\n",
    "    final_train_prompts = ['' for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train empty', generated_sequence)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 information in the doc which enables to answer the question but not good response often in-context\n",
    "# 2 information in the doc which enables to answer the question and good response often in-context\n",
    "# 3 Hard negative passage\n",
    "# 4 Same\n",
    "\n",
    "# prompt_prefix = \"Query: who wrote the song photograph by ringo starr\\nAnswer: Ringo Starr\\n\\nQuery: who is playing the halftime show at super bowl 2016\\nAnswer: Coldplay\\n\\nQuery: where was the world economic forum held this year\\nAnswer: Davos\\n\\nQuery: where are the giant redwoods located in california\\nAnswer: Humboldt County\\n\\nQuery: who has made the most premier league appearances\\nAnswer: Gareth Barry\\n\\nQuery: \"\n",
    "# prompts = ['who has most followers on instagram in world','who did the united states win its independence from', 'locations for the film an englishman who went up a hill', 'who is the valley of the dolls based on']\n",
    "# final_prompts = [prompt_prefix + prompt + '\\nAnswer:' for prompt in prompts]\n",
    "\n",
    "# text_conditioning = [\"This list contains the top 50 accounts with the most followers on the photo and video-sharing social platform Instagram. As of July 2019, the most followed user is Instagram's own account, with over 308 million followers. Cristiano Ronaldo is the most followed individual, with over 177 million followers. Fifteen accounts have exceeded 100 million followers on the site.\",\n",
    "#                      \"During the American Revolution, the legal separation of the thirteen colonies from Great Britain in 1776 actually occurred on July 2, when the Second Continental Congress voted to approve a resolution of independence that had been proposed in June by Richard Henry Lee of Virginia declaring the United States independent from Great Britain's rule. After voting for independence, Congress turned its attention to the Declaration of Independence, a statement explaining this decision, which had been prepared by a Committee of Five, with Thomas Jefferson as its principal author. Congress debated and revised the wording of the Declaration, finally approving it two days later on July 4. A day earlier, John Adams had written to his wife Abigail\",\n",
    "#                      'The village was a primary location for the making of the film \\\"The Englishman Who Went Up a Hill But Came Down a Mountain\\\", which starred Hugh Grant. The hilltop scenes were filmed on the Gyrn, the long hill that overlooks the village. It was also featured in \\\"Monk\\'s Hood\\\", an episode of \\\"The Cadfael Chronicles\\\"',\n",
    "#                      'Valley of the Dolls is the first novel by American writer Jacqueline Susann. Published in 1966, the book was the biggest selling novel of its year. To date, it has sold more than 31 million copies, making it one of the best-selling works in publishing history.']\n",
    "\n",
    "# answers = ['Instagram','Great Britain',\"Llansilin in Powys\",[\"Judy Garland\", \"Carole Landis\", \"Dean Martin\", \"Ethel Merman\"]]\n",
    "\n",
    "n_passages = 4\n",
    "eval_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_valid.jsonl'\n",
    "train_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_train.jsonl'\n",
    "train_passage = []\n",
    "valid_passage = []\n",
    "with open(train_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        train_passage.append(json.loads(line)['text'].split('\\n\\n')[1])\n",
    "        \n",
    "with open(eval_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        valid_passage.append(json.loads(line)['text'].split('\\n\\n')[1])\n",
    "        \n",
    "tests = [{'w_embeds': True, 'temperature': 0 },  {'w_embeds': True, 'temperature': 0.7 }, {'w_embeds': False, 'temperature': 0.7 }]\n",
    "# print('Train passage:', train_passage)\n",
    "# print('Valid passage:', valid_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioning = ['Kyutai is a non-profit laboratory dedicated to open research in AI, founded in November 2023 by the iliad Group, CMA CGM and Schmidt Sciences. Launched with an initial team of six leading scientists, who have all worked with Big Tech labs in the USA, Kyutai continues to recruit at the highest level, and also offers internships to research Master’s degree students.']*4\n",
    "prompts = ['who are the founders of Kyutai?', 'when was Kyutai founded?', 'how many scientists were in the initial team?', 'what does Kyutai offer to research Master’s degree students?']\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "generated_sequence = pipeline.generate(prompts = prompts,\n",
    "                                      text_conditioning = conditioning,\n",
    "                                      temperature = 0.5, \n",
    "                                      max_tokens =200,\n",
    "                                      truncate_double_space = False)\n",
    "# random_flip, put the number of the token to flip. \n",
    "print(generated_sequence)\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "generated_sequence, logprobs = pipeline.generate(prompts = ['who has most followers on Instagram in world?'],\n",
    "                                      text_conditioning = [\"This list contains the top 50 accounts with the most followers on the photo and video-sharing social platform Instagram. As of July 2019, the most followed user is Instagram's own account, with over 308 million followers. Cristiano Ronaldo is the most followed individual, with over 177 million followers.\"],\n",
    "                                      temperature = 0.4, \n",
    "                                      max_tokens =200,\n",
    "                                      truncate_double_space = False)\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param: {'w_embeds': True, 'temperature': 0}\n",
      "Passage The Roman Republic (Repubblica Romana) was a sister republic of the First French Republic. It was pr  | Truth oclaimed on 18 February 1798 after Louis-Alexandre Berthier, a general of Napoleon, had occupied the\n",
      "Valid  word ['the first Roman Republic in 509 BC, and the first Roman Republic was established. The Roman Republic was a period of great expansion for Rome.']\n",
      "Valid  empty ['# 1910 in Romanian literature\\n\\nThis article presents a list of the literary events and publications of Romania in 1910.']\n",
      "Passage Cochamó is a Chilean town and commune located in Llanquihue Province, Los Lagos Region. The capital   | Truth of the commune is the town of Río Puelo, which is named after the Puelo River.\n",
      "Train word ['the province of Chile is located in the Coquimbo Region, in the Limarí Province, in the Ovalle commune.']\n",
      "Train empty ['# 1999 Chilean local elections\\n\\nThe **1999 Chilean local elections** were held on 19 December 1999.']\n",
      "Param: {'w_embeds': True, 'temperature': 0.7}\n",
      "Passage The Roman Republic (Repubblica Romana) was a sister republic of the First French Republic. It was pr  | Truth oclaimed on 18 February 1798 after Louis-Alexandre Berthier, a general of Napoleon, had occupied the\n",
      "Valid  word ['as the first modern Roman republic, the Roman Republic was a political system in ancient Rome that lasted for nearly 500 years, from 509 BC to 27 BC.']\n",
      "Valid  empty ['## Details\\n\\nThe Roman Republic was one of the most powerful states of the ancient world, and its influence can be seen in the legal systems of modern nations.']\n",
      "Passage Cochamó is a Chilean town and commune located in Llanquihue Province, Los Lagos Region. The capital   | Truth of the commune is the town of Río Puelo, which is named after the Puelo River.\n",
      "Train word ['Cochamó is located in the south of Chile, in the commune of Cochamó, province of Llanquihue, in the Los Lagos Region.']\n",
      "Train empty ['## The New York Times has published a profile of the Chilean town of La Ligua, which has been chosen to host the 2018 edition of the Cocamelon festival.']\n",
      "Param: {'w_embeds': False, 'temperature': 0.7}\n",
      "Passage The Roman Republic (Repubblica Romana) was a sister republic of the First French Republic. It was pr  | Truth oclaimed on 18 February 1798 after Louis-Alexandre Berthier, a general of Napoleon, had occupied the\n",
      "Valid  word ['\"the first and only truly successful mass-market, mass-produced sports car\", the Porsche 911 was introduced in 1963 as the Porsche 901. It was a thoroughly modern sports car, with a flat-six engine mounted behind the rear axle and a rear-mounted transaxle, a layout that was unusual for the time. The car was an instant success, and Porsche sold over 100,000 911s in its first decade of production.\\n\\nIn 1964, Porsche changed the name of the 901 to 911, to avoid a potential conflict with French car maker Peugeot, which had a trademark on the name \"00\". The 911 was available in coupe and targa body styles, and a convertible was added in 1982. The 9']\n",
      "Valid  empty [\"## Your one-stop shop for all your building needs\\n\\nThe company was founded in 1947 by George H. Hosseini. Today, his son, George H. Hosseini Jr., is the CEO.\\n\\nThe company started out as a small lumberyard in the heart of downtown Los Angeles. It was a family-owned business that focused on providing building materials for residential and commercial construction projects.\\n\\nThe company's first major project was the construction of the Los Angeles Memorial Coliseum. It was the first time that the company had worked on such a large project.\\n\\nOver the years, the company has grown and expanded. It now has 15 locations in Southern California and Nevada.\\n\\nThe company's headquarters are in downtown Los Angeles.\\n\\nProducts and services\\n\\nThe company provides a wide range of building materials and services.\\n\\nProducts: \\n - Lumber\\n - Ply\"]\n",
      "Passage Cochamó is a Chilean town and commune located in Llanquihue Province, Los Lagos Region. The capital   | Truth of the commune is the town of Río Puelo, which is named after the Puelo River.\n",
      "Train word [\"the year 2006.\\n\\nEarly life\\n\\nBorn in Gauteng, South Africa, he was educated at St. Stithians College. He was an all-rounder at the school and was selected to represent the school's 1st XI cricket team. He also represented the school's 1st XV rugby team. He was also a member of the school's athletics team.\\n\\nEarly career\\n\\nUpon leaving school, he studied at the University of Cape Town. He also played for the university's cricket team. He was a member of the 1st XI team which won the 1994–95 University Sports South African University Championship. He was also a member of the 1st XV rugby team.\\n\\nIn 1995, he moved to the United Kingdom. He played club cricket for the Kent Cricket Club. He also played for the club's\"]\n",
      "Train empty ['## Latest revision as of 16:47, 13 September 2012\\n\\nThe first documented use of the name \"Meadowbrook\" was in 1906, when it was used as the name of a planned subdivision in the northwest corner of the city. This name was used for the area for many years, but in 1922, the name \"Meadowbrook\" was officially adopted for the entire area.\\n\\nThe first major development in Meadowbrook was the construction of a streetcar line in 1908. The line was constructed by the Seattle and Lake Washington Railway and Navigation Company, which was the predecessor of the Seattle, Lake Washington and Northern Railway. The line ran from downtown Seattle along the north shore of Lake Washington to the area of Meadowbrook. It was originally named the \"Lake Washington Line\", but was later renamed']\n"
     ]
    }
   ],
   "source": [
    "# Continuation\n",
    "for param in tests:\n",
    "    print('Param:', param)\n",
    "    if param['w_embeds']:\n",
    "        pipeline.pipeline_args.w_embeds = True\n",
    "    else:\n",
    "        pipeline.pipeline_args.w_embeds = False\n",
    "    \n",
    "    final_valid_prompts = [passage[100:].split(' ')[0] for passage in valid_passage][2] \n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    print('Passage', text_valid_conditioning, ' | Truth', [passage[100:200] for passage in valid_passage][2] )\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  word', generated_sequence)\n",
    "    \n",
    "    final_valid_prompts = ['' for passage in train_passage][2]\n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  empty', generated_sequence)\n",
    "\n",
    "    final_train_prompts =  [passage[100:].split(' ')[0] for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    print('Passage', text_train_conditioning, ' | Truth', [passage[100:200] for passage in train_passage][1] )\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train word', generated_sequence)\n",
    "    final_train_prompts = ['' for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train empty', generated_sequence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
