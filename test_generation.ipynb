{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippolytepilchen/micromamba/envs/llm_embed/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from embed_llm.models.augmented_model import EmbedAugPipeline\n",
    "from embed_llm.generation.evaluation import  ensure_reproducibility\n",
    "from bertviz import head_view, model_view # type: ignore\n",
    "from embed_llm.models.mistral.generate import get_attention\n",
    "from embed_llm.generation.metrics import (\n",
    "    word_overlap,\n",
    "    get_bleu_score,\n",
    "    get_meteor,\n",
    "    get_em,\n",
    "    get_f1_score,\n",
    "    metric_max_over_ground_truths,\n",
    "    get_approx_em\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from embed_llm.generation.evaluation import (create_prompt, create_prompt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_reproducibility(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 for loading\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Must have a params json for pipeline\n",
    "llm_path = '/lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B'\n",
    "\n",
    "\n",
    "\n",
    "# run_name = 'ToyPretraining_LLM_False_Emb_False_MaxEmb_1_0.2cont_0alpha_16BS_tmp' # Best one embed \n",
    "run_name = 'ToyInstruct_LLM_False_Emb_False_MaxEmb_3_alpha_2'\n",
    "# run_name = 'ToyPretraining_LLM_False_Emb_False_MaxEmb_3_fullcont_16BS_alternativeCA'\n",
    "# run_name = 'ToyPretraining_LLM_False_Emb_False_MaxEmb_3_fullcont_16BS'\n",
    "# run_name = 'ToyPretraining_LLM_False_Emb_False_MaxEmb_3_fullcont_16BS_beginCA'\n",
    "# run_name = 'DistillTraining_mid_MaxEmb_3_50cont_0alpha_1tmp'\n",
    "# run_name = 'ToyPretraining_LLM_False_Emb_False_MaxEmb_3_fullrec_16BS'\n",
    "# run_name = None\n",
    "\n",
    "last_ckpt = '010000' # '008500' #'010000' \n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.device('cuda:0')\n",
    "    print(f'Using {device} for loading')\n",
    "\n",
    "w_embeds = True\n",
    "max_batch_size = 4\n",
    "instruct_ckpt = None\n",
    "# instruct_ckpt = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/Instruct_mid_1embeds_alpha0_lowlr_newdata/checkpoints/checkpoint_010000'\n",
    "# instruct_ckpt =\"/lustre/scwpod02/client/kyutai-interns/hippop/tmp/ToyDecompressingTests_LLM_FT_MaxEmb_true_reversed/checkpoints/checkpoint_020000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If n_layers is 1, hidden_dim must be equal to out_dim, \n",
      " but hidden_dim is not equal to out_dim so hidden_dim is set to out_dim\n",
      "Loading MLP projector\n"
     ]
    }
   ],
   "source": [
    "pipeline: EmbedAugPipeline = EmbedAugPipeline.load_inference_model(\n",
    "    llm_path=llm_path,\n",
    "    ckpt_path= None if run_name is None else (\"/lustre/scwpod02/client/kyutai-interns/hippop/tmp/\"\n",
    "    + run_name\n",
    "    + \"/checkpoints/checkpoint_\"\n",
    "    + last_ckpt),\n",
    "    device=device,\n",
    "    llm_name=\"Mistral7B\",\n",
    "    embed_model_name=\"NVEmbed\",  # Not used if pretrainde ckpt available\n",
    "    max_batch_size=max_batch_size,\n",
    "    instruct_ckpt=instruct_ckpt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_data = \"/lustre/scwpod02/client/kyutai-interns/hippop/processed_data/factkg_NVEmbed/factkg_test.jsonl\"\n",
    "eval_data = '/lustre/scwpod02/client/kyutai-interns/hippop/processed_data/eval_QA_NVEmbed/nq_open_data.jsonl' # nq_data.jsonl\n",
    "context = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "\n",
    "with open(eval_data, \"r\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                questions.append(data[\"question\"].strip())\n",
    "\n",
    "                if isinstance(data[\"answer\"], str):\n",
    "                    answers.append([data[\"answer\"].strip()])\n",
    "\n",
    "                elif isinstance(data[\"answer\"], list):\n",
    "                    answers.append(data[\"answer\"])\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid answer type\")\n",
    "                # Take the first ranked retrieved passage\n",
    "                context.append(data[\"passages\"][:5])\n",
    "\n",
    "c = list(zip(questions, context, answers))\n",
    "fixed_random = random.Random(0.2)\n",
    "fixed_random.shuffle(c)\n",
    "questions, context, answers = zip(*c)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Prefix:\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippolytepilchen/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v2/5130cf1daf847c1bacee854a6ef1ca939e747fb2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([11.6470, 11.2076, 10.6460,  9.6272,  9.5174], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17560>\n",
      "Next token: tensor([ 1183,  1778,  1183, 14602], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([16.1400, 13.3183, 11.6442, 10.7116,  9.3307], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5fbc040>\n",
      "Next token: tensor([3734, 1363, 4802, 4653], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([11.9176, 11.4700, 11.2775, 11.1665, 10.9681], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5fbcfe0>\n",
      "Next token: tensor([1171, 1081, 1171,    2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([8.5119, 8.1174, 7.2827, 7.2628, 6.9641], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12980>\n",
      "Next token: tensor([ 5948,  9779,  5009, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([8.2752, 8.0402, 7.8685, 7.5480, 7.4066], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5e177e0>\n",
      "Next token: tensor([ 1065, 15201,  1254,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([14.2575,  9.6915,  9.1627,  8.8942,  8.5660], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x155550cbf650>\n",
      "Next token: tensor([25480,  1117,  9514, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([8.6689, 8.0179, 7.9344, 7.7046, 6.8951], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5fbfbf0>\n",
      "Next token: tensor([ 1152,  2187, 29492,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([16.2626, 10.1835,  9.1709,  8.8220,  8.3151], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5fbc180>\n",
      "Next token: tensor([ 9005,  1065, 24815, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([8.9128, 7.9126, 7.9046, 7.7661, 6.6805], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5ed0d60>\n",
      "Next token: tensor([29478,  1040,  1072,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([16.9298, 10.6716,  9.6189,  8.9287,  8.5512], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5fbf510>\n",
      "Next token: tensor([29493,  1876,  6544, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.2497, 8.3027, 8.1700, 7.6029, 6.8246], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550df46ede0>\n",
      "Next token: tensor([11805, 25280, 13636,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([17.0635, 10.7811,  9.7250,  8.9269,  8.8674], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28c20>\n",
      "Next token: tensor([ 2353,  1096, 11374, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.3716, 8.3033, 8.2277, 7.4107, 7.0388], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550df34e520>\n",
      "Next token: tensor([29493,  1276, 29491,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([17.5122, 11.1208,  9.8324,  9.2942,  8.9078], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b9c0>\n",
      "Next token: tensor([ 1083,  3066,     2, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.4705, 8.2153, 8.1191, 7.5734, 7.2769], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([4838, 1070, 4855,    2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([17.7789, 11.2310,  9.8544,  9.5592,  9.0006], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5fbfbf0>\n",
      "Next token: tensor([ 1159,  4369, 29473, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.5317, 8.1844, 7.9292, 7.8848, 7.4445], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a451c0>\n",
      "Next token: tensor([29493, 26751, 29508,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([17.9971, 11.4036,  9.8701,  9.7967,  9.0340], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550df34f420>\n",
      "Next token: tensor([13956,  9550, 29502, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.6515, 8.2618, 8.2528, 7.8115, 7.5548], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([29493, 29491, 18529,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([18.2190, 11.6128, 10.0095,  9.8686,  9.0505], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([ 1072,     2,  1697, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.6797, 8.5922, 8.1750, 8.1727, 7.4886], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46020>\n",
      "Next token: tensor([6497,    2, 3746,    2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([18.4401, 11.9835, 10.0135,  9.6958,  9.1290], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46020>\n",
      "Next token: tensor([10247, 29554, 29567, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([9.6907, 8.7466, 8.3640, 8.1322, 7.6807], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28db0>\n",
      "Next token: tensor([29491,     2,     2,     2], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([4, 32768])\n",
      "Top k prelogits: tensor([18.6638, 12.1349, 10.0538,  9.7803,  9.2702], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d170>\n",
      "Next token: tensor([    2, 29554,  4855, 29571], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Generated tokens: [[1183, 3734, 1171, 5948, 1065, 25480, 1152, 9005, 29478, 29493, 11805, 2353, 29493, 1083, 4838, 1159, 29493, 13956, 29493, 1072, 6497, 10247, 29491], [1778, 1363, 1081, 9779, 15201, 1117, 2187, 1065, 1040, 1876, 25280, 1096, 1276, 3066, 1070, 4369, 26751, 9550, 29491, 2, 2, 29554, 2], [1183, 4802, 1171, 5009, 1254, 9514, 29492, 24815, 1072, 6544, 13636, 11374, 29491, 2, 4855, 29473, 29508, 29502, 18529, 1697, 3746, 29567, 2], [14602, 4653, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2, 29571, 2]]\n",
      "GENERATION\n",
      "Given Query: fast and furious 7 red car abu dhabi\n",
      "GT Answer: ['The Lykan Hypersport']\n",
      "Context Given [\"July 2019, Abu Dhabi allocated $163 million to finance global entertainment partners as part of its plan to diversify the economy and wean it off oil. Many Hollywood and other national film production teams have used parts of the UAE as filming locations. Neighboring Dubai gets a lot of attention, but in recent years Abu Dhabi has become a popular destination. The Etihad Towers and Emirates Palace Hotel were some of the city's landmarks used as filming locations for the movie Furious 7, in which cars rush through the building and smashed through the windows of the towers. In 2018,\", \"to appear in the film Furious 7, one of which is available for public viewing at the W Motors Gallery in Dubai. It is the most expensive car ever featured in the Fast and the Furious films, though the vehicles seen on screen were driveable stunt models rather than production vehicles. The Lykan HyperSport's first pre-production model debuted at the Dubai International Motor Show on 5 October 2013. Other venues where the Lykan HyperSport was displayed include the Dubai International Boat Show in the United Arab Emirates; the Historical, Vintage, and Classical Cars Museum in Kuwait; and Cohen&Cunil in Marbella, Spain.\", 'Portrayed in Furious 7, many action scenes are filmed here.', 'After wrapping up the Mumbai schedule, the filming team left for Abu Dhabi. The Abu Dhabi schedule of shooting was intense and action-packed. In Abu Dhabi, filming started early May, and took place at various locations in Abu Dhabi including the Corniche, Liwa oasis, Hyatt Capital Gate Hotel, Qasr al Sarab, Emirates Palace and Yas Island. In one of the chase sequences in the film, 120 cars were involved. The film also had used Formula 1 cars. Even after the brain surgery, all the stunts were performed by Roshan himself. The stunts were designed by Andy Armstrong and shot in Abu Dhabi. The Abu Dhabi', \"A Lykan HyperSport was featured in the film Fast and Furious 7. The film's car coordinator Dennis McCarthy explained in an interview that the Lykan HyperSports used in the film were not production models but purpose-built by W Motors for the film using the same moulds, but cheaper material (fibreglass instead of carbon fibre) and a simpler chassis. Of the ten produced for the film, one was returned to W Motors and is displayed in their showroom. The other nine were destroyed during the course of filming. Several Lykan HyperSport replicas were also used in the 2018 British Fast & Furious Live show. At least one has since been sold and was imported to the United States by Sam Hard (Hard Up Garage) and Ed Bolian (VINwiki). It will be built into a driveable car using an extensively modified Porsche Boxster chassis by Casey Putsch and Genius Garage under license from W Motors. The build is being documented on YouTube.\"][...]\n",
      "Answer in context? 1 \n",
      "Prediction: The film was shot in Abu Dhabi, Dubai, Iceland, Georgia, and Los Angeles. \n",
      "\n",
      "\n",
      "Given Query: where is arachidonic acid found in the body\n",
      "GT Answer: ['brain', 'muscles', 'liver']\n",
      "Context Given [\"Arachidonic acid (arachidonic's) has 20 carbons, is present in animal visceral fat (brain, liver, kidney, lung, spleen), and is a 5,8,11,14-tetra-unsaturated fatty acid. I caused by the decomposition of cell membrane in the phospholipid. Prostaglandin, and important as starting materials for the thromboxane, leukotriene such as are known as a series of metabolic pathway to give eicosanoids, arachidonic acid cascade are compounds. C19H31CO2H, IUPAC organization name (5Z , 8Z , 11  Z , 14Z)-icosa-5,8,11,14-tetraenoic acid, numerical representation 20: 4 (5,8,11,14), n-6, molecular weight 304.47, boiling point 169- 171 °C. CAS Registry Number 506-32-1.\", \"Arachidonic acid is a polyunsaturated fatty acid present in the phospholipids (especially phosphatidylethanolamine, phosphatidylcholine, and phosphatidylinositides) of membranes of the body's cells, and is abundant in the brain, muscles, and liver. Skeletal muscle is an especially active site of arachidonic acid retention, accounting for roughly 10-20% of the phospholipid fatty acid content typically. In addition to being involved in cellular signaling as a lipid second messenger involved in the regulation of signaling enzymes, such as PLC-γ, PLC-δ, and PKC-α, -β, and -γ isoforms, arachidonic acid is a key inflammatory intermediate and can also act as a vasodilator. (Note separate synthetic pathways, as described in section below.)\", 'Arachidonic acid (AA, sometimes ARA) is a polyunsaturated omega-6 fatty acid 20:4(ω-6), or 20:4(5,8,11,14). It is structurally related to the saturated arachidic acid found in cupuaçu butter. Its name derives from the New Latin word arachis (peanut), but it is important to note that peanut oil does not contain any arachidonic acid.', 'acids (EETs) by epoxygenase. Arachidonic acid is freed from phospholipid by hydrolysis, catalyzed by the phospholipase A2 (PLA2). Arachidonic acid for signaling purposes appears to be derived by the action of group IVA cytosolic phospholipase A2 (cPLA2, 85 kDa), whereas inflammatory arachidonic acid is generated by the action of a low-molecular-weight secretory PLA2 (sPLA2, 14-18 kDa). Arachidonic acid is a precursor to a wide range of eicosanoids: The production of these derivatives and their actions in the body are collectively known as the \"arachidonic acid cascade\"; see essential fatty acid interactions and the enzyme and metabolite linkages given in the previous paragraph for more details.', 'Arachidonic acid is marketed as an anabolic bodybuilding supplement in a variety of products. Supplementation of arachidonic acid (1,500 mg/day for eight weeks) has been shown to increase lean body mass, strength, and anaerobic power in experienced resistance-trained men. This was demonstrated in a placebo-controlled study at the University of Tampa. Thirty men (aged 20.4 ± 2.1 years) took arachidonic acid or a placebo for eight weeks, and participated in a controlled resistance-training program. After eight weeks, lean body mass (LBM) had increased significantly, and to a greater extent, in the AA group (1.62 kg) vs. placebo (0.09 kg) (p<0.05). The change'][...]\n",
      "Answer in context? 1 \n",
      "Prediction: Arachidonic acid is found in the phospholipids of cell membranes.т \n",
      "\n",
      "\n",
      "Given Query: who wrote cant get you out of my head lyrics\n",
      "GT Answer: ['Cathy Dennis and Rob Davis', 'Rob Davis', 'Cathy Dennis']\n",
      "Context Given ['\"Can\\'t Get You Out of My Head\" is a song that was recorded by Australian singer Kylie Minogue for her eighth studio album Fever (2001). Parlophone Records released the song as the album\\'s lead single on 8 September 2001. \"Can\\'t Get You Out of My Head\", which was written and produced by Cathy Dennis and Rob Davis, is a dance-pop, techno-pop and neo-disco song that is known for its \"la la la\" hook. Its lyrics are about obsession with a love interest. Music critics praised the song\\'s production and Minogue\\'s vocals and labelled it a highlight of Fever. The song reached number one on charts in 40 countries worldwide. It peaked at number one on the UK Singles Chart for four weeks and was certified two-times platinum by the British Phonographic Industry (BPI). It also topped the', 'In 2000, British singer-songwriter Cathy Dennis and English songwriter Rob Davis had been brought together by Universal Publishing to work on new music. The session for \"Can\\'t Get You Out of My Head\" began with Davis generating a 125 bpm drum loop using the computer program Cubase. Dennis improvised with the line \"I just can\\'t get you out of my head\", which later became the song\\'s lyric. After three and a half hours, Davis and Dennis had recorded the demo for \"Can\\'t Get You Out of My Head\" and the vocals were recorded the same day; the pair said the recording process was \"very natural and fluid\", and did not rely on heavy instrumentation. Prior', '\"Can\\'t Get You Out of My Head\" is three minutes and fifty seconds long. In their book The New Rolling Stone Album Guide, Nathan Brackett and Christian David Hoard labelled it a neo-disco track. Justin Myers of the Official Charts Company characterized it as a dance-pop song, while Stereogum\\'s Tom Breinan described it as a techno-pop anthem. \"Can\\'t Get You Out of My Head\" is written in the key of D minor. The song, which does not follow the common verse–chorus structure, is composed of numerous fragmented sections. According to Davis, it \"breaks a few rules as it starts with a chorus and in comes the \\'la\\'s\\'\". Minogue chants a \"la la la\" hook that is often noted', 'the song\\'s most appealing part by music critics. According to BBC Radio 2, the song\\'s composition is \"deceptively simple, but its veins run with the whole history of electronic music\". The writer described the song\\'s bassline as \"pulsing\" and influenced by the music of English rock band New Order and German electronic music band Kraftwerk. \"Can\\'t Get You Out of My Head\" is about an obsession with an unknown person, who according to The Guardian\\'s Dorian Lansky could be \"a partner, an evasive one-night stand or someone who doesn\\'t know [the song\\'s narrator] exists\". Writing for the same newspaper, Everett True identified a \"darker element\" in the simple lyrics and said this sentiment is echoed in Minogue\\'s', 'the Herald Sun, Cameron Adams placed \"Can\\'t Get You Out of My Head\" at the top of his list of Minogue\\'s best songs and called it \"a happy accident\". Adams wrote, \"if you could program a computer to formulate the perfect pop song, it would sound like this\". Reviewing The Abbey Road Sessions version of the song, Tim Sendra of AllMusic said the \"most interesting reboot\" on the album took place on \"Can\\'t Get You Out of My Head\", saying the \"insistent strings push the song along with tightly coiled electricity that is impossible to resist\". Sal Cinquemani of'][...]\n",
      "Answer in context? 1 \n",
      "Prediction: The song was written by Cathy Dennis and Robbie Williams.ще 10 лет назад \n",
      "\n",
      "\n",
      "Given Query: who has the most big ten championships in football\n",
      "GT Answer: ['Michigan']\n",
      "Context Given ['8× National Champions: 1942, 1954, 1957, 1961, 1968, 1970, 2002, 2014 ; 39× Big Ten Champions: 1916, 1917, 1920, 1935, 1939, 1942, 1944, 1949, 1954, 1955, 1957, 1961, 1968–1970, 1972–1977, 1979, 1981, 1984, 1986, 1993, 1996, 1998, 2002, 2005–2009, 2010 (vacated), 2014, 2017–2020 ; 2× Leaders Division Champions: 2012, 2013 ; 6× East Division Champions: 2014–2019 ; 2× OAC Champions: 1906, 1912', 'Most wins in college football history (976) ; Most winning seasons of any program (121) ; Most appearances in the final AP Poll (61) ; More conference titles in the Big Ten than any other FBS program with a single conference (43) ; One of only six programs with a winning record against every FBS conference', 'Big Ten Championships (4): ; 1995, 1997, 2008, 2016', 'This list goes through the 2020 season. † Ohio State vacated 12 wins and its Big Ten title in 2010 due to NCAA sanctions. †† Numbers of division and conference championships shown reflect Big Ten history only and do not include division and conference championships in former conferences. Maryland and Rutgers joined the Big Ten in 2014, and Nebraska joined in 2011. Number of Claimed National Championships, as well as win-loss-tie records, include all seasons played, regardless of conference membership.', 'Ohio State joined the Big Ten in 1912; before that they were a member of the Ohio Athletic Conference and won two OAC titles. Ohio State has won a championship in the Big Ten 39 times, second-most in the conference and third most conference titles of any school in any conference. † Co-champions'][...]\n",
      "Answer in context? 0 \n",
      "Prediction: Ohio Stateмммммммммм \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_embeds = True\n",
    "temp = 0\n",
    "max_tokens = 64\n",
    "max_embeds = 3\n",
    "icl_examples = 0\n",
    "max_bs = 4\n",
    "rag = False\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "other_device = device if device_count <= 1 else torch.device(\"cuda:1\")\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "    \n",
    "prompt_prefix = create_prompt_prefix(\n",
    "    queries=questions,\n",
    "    answers=[answer[0] for answer in answers],\n",
    "    docs=context if rag and not w_embeds else None,\n",
    "    max_examples=icl_examples,\n",
    ")\n",
    "\n",
    "generated_sequences = []\n",
    "\n",
    "queries = list(questions[icl_examples:])\n",
    "docs = list(context[icl_examples:])\n",
    "truths = list(answers[icl_examples:])\n",
    "queries.reverse()\n",
    "docs.reverse()\n",
    "truths.reverse()\n",
    "\n",
    "if w_embeds:\n",
    "\n",
    "    no_context_prompt = [\n",
    "        create_prompt(\n",
    "            prefix=prompt_prefix, doc=\"\", query=query, wdoc=False\n",
    "        )\n",
    "        for query in queries[:max_bs]\n",
    "    ]\n",
    "\n",
    "    context_prompt = [\n",
    "        create_prompt(\n",
    "            prefix=\" answer the question following the examples:\\n\\n\"\n",
    "            + prompt_prefix,\n",
    "            doc=\"\",\n",
    "            query=query,\n",
    "            wdoc=False,\n",
    "        )\n",
    "        for query in queries[:max_bs]\n",
    "    ]\n",
    "\n",
    "else:\n",
    "\n",
    "\n",
    "    no_context_prompt = [\n",
    "        create_prompt(\n",
    "            prefix=prompt_prefix,\n",
    "            doc=doc if rag else '',\n",
    "            query=query,\n",
    "            wdoc=True,\n",
    "        )\n",
    "        for query, doc in zip(\n",
    "            queries[:max_bs],\n",
    "            docs[:max_bs],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "# for i, cont in enumerate(context_prompt if pipeline.pipeline_args.w_prefix_prompt else no_context_prompt):\n",
    "#     print(f'{i}',cont)\n",
    "\n",
    "\n",
    "print('Prompt Prefix:\\n', prompt_prefix)\n",
    "    # print(no_context_prompt[i] if not pipeline.pipeline_args.w_prefix_prompt else context_prompt[i])\n",
    "    # print(f'Ground truth answer: {a}\\n')\n",
    "generated_sequence = pipeline.generate(\n",
    "    prompt_pre_embed= (['']*len(queries[:max_bs]) if not pipeline.pipeline_args.w_prefix_prompt \n",
    "        else ['Based on the context ']*len(queries[:max_bs])),\n",
    "    prompt_post_embed = context_prompt if pipeline.pipeline_args.w_prefix_prompt else no_context_prompt,\n",
    "    text_conditioning= [doc[:max_embeds] for doc in docs[:max_bs]] if w_embeds else None,\n",
    "    temperature=temp,\n",
    "    max_tokens=max_tokens,\n",
    "    truncate_line=False,\n",
    "    device=device,\n",
    "    device_generation=other_device,\n",
    ")\n",
    "\n",
    "print('GENERATION')\n",
    "for i, (q, a, d, g) in enumerate(zip(queries[:max_bs], truths[:max_bs], docs[:max_bs], generated_sequence)):\n",
    "    print(f'Given Query: {q}\\nGT Answer: {a}\\nContext Given {d}[...]\\nAnswer in context? {get_approx_em(d,a[0])}','\\nPrediction:', g, '\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.6512, 12.4910, 12.1713, 12.0596, 11.2013], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d151c0>\n",
      "Next token: tensor([1190, 1190, 1190], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([8.8163, 8.4985, 7.8411, 7.7368, 7.6940], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d5d0>\n",
      "Next token: tensor([29508, 29473, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.4975, 12.2047, 11.3879, 11.3865, 10.9379], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44ae0>\n",
      "Next token: tensor([29502, 29508, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.8514, 10.5815,  9.4857,  9.4694,  9.3502], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12070>\n",
      "Next token: tensor([29502, 29502, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.7575, 11.2477, 11.0387, 11.0038, 10.9680], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11e40>\n",
      "Next token: tensor([29502, 29502, 29552], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.5781, 12.5142, 12.1886, 12.0430, 11.9746], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d178d0>\n",
      "Next token: tensor([29502, 29591, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([9.2730, 8.9244, 8.8795, 8.8636, 8.1496], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16ed0>\n",
      "Next token: tensor([29502,  1135,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.3358,  9.1286,  8.8988,  8.5240,  7.6452], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d15f80>\n",
      "Next token: tensor([29502,  1250,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([9.7223, 9.1367, 9.1304, 8.8182, 8.5889], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e660>\n",
      "Next token: tensor([29502,  1753,  1832], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.1130, 10.1127,  9.8874,  8.9222,  8.5975], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14a90>\n",
      "Next token: tensor([29502, 29476, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.0964, 14.0650, 13.0824, 13.0052, 12.6886], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17f10>\n",
      "Next token: tensor([29502, 28950, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.0888, 11.2331, 10.6114, 10.0811,  9.7645], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46ed0>\n",
      "Next token: tensor([29502,   781, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.8068, 11.6807, 11.2766, 10.3892, 10.3499], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d15a30>\n",
      "Next token: tensor([29502,   781, 29552], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.6252, 14.1037, 13.4211, 13.0541, 12.5640], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ed40>\n",
      "Next token: tensor([29502, 29544, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.3179,  8.9865,  8.5045,  8.4593,  8.3707], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44180>\n",
      "Next token: tensor([29502, 29508,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.7463, 10.1951,  9.3219,  8.6390,  7.7745], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17560>\n",
      "Next token: tensor([29502, 29502,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.5935, 10.1360, 10.1130, 10.0062,  9.6149], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12070>\n",
      "Next token: tensor([29502, 29491, 28100], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.3669,  9.9021,  9.4773,  9.1176,  8.9274], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c360>\n",
      "Next token: tensor([29502, 29502, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.0408, 14.2349, 13.1640, 12.7918, 12.6191], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12700>\n",
      "Next token: tensor([29502, 29502, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.9435, 11.3721, 10.5002, 10.0322,  9.9092], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16430>\n",
      "Next token: tensor([29502,   781, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.6779, 11.4110, 11.0990, 10.1885, 10.1673], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a10590>\n",
      "Next token: tensor([29502,   781, 29552], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.5264, 13.8990, 13.1002, 12.7629, 12.2525], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46020>\n",
      "Next token: tensor([29502,  5621, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.1761,  8.8940,  8.8152,  8.2934,  8.0540], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d167f0>\n",
      "Next token: tensor([29502, 29476,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.4932, 10.9597, 10.7665,  9.3734,  8.6322], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45620>\n",
      "Next token: tensor([29502, 12256,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.4704, 10.4288, 10.2151,  9.7774,  9.6379], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45260>\n",
      "Next token: tensor([29502,  1117,  2768], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.5444, 11.5656, 11.2243,  9.9968,  9.4479], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  1032,  1254], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.1576, 10.3049,  9.4809,  8.8390,  8.8029], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17380>\n",
      "Next token: tensor([29502,  4997,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.2355, 15.8587, 10.3214, 10.1665,  9.7515], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11620>\n",
      "Next token: tensor([29502,  7138, 16129], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.2792, 14.2354, 11.8175, 11.4839, 10.7099], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14bd0>\n",
      "Next token: tensor([29502, 25849,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([23.9972, 10.6873,  9.7316,  9.5278,  8.2780], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a104a0>\n",
      "Next token: tensor([29502,  1245,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.3966, 10.2240,  9.7078,  9.5027,  9.2347], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d15a30>\n",
      "Next token: tensor([29502,  1040, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.3766, 11.0415, 10.4123, 10.3664, 10.3006], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d15d50>\n",
      "Next token: tensor([29502, 10014, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.7358, 10.7960, 10.6364, 10.1377,  9.9070], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12020>\n",
      "Next token: tensor([29502,  1070, 29552], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.4376, 13.2801, 12.2138, 11.9198, 11.3605], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17dd0>\n",
      "Next token: tensor([29502,  1040, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.5726, 10.4420,  9.5244,  9.3914,  9.0429], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d15080>\n",
      "Next token: tensor([29502,  9391,  1171], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.8635, 13.1942, 12.3601, 11.1722, 10.5215], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a7a0>\n",
      "Next token: tensor([29502,  1398,  1032], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.2340, 11.7585, 11.4667, 11.2928, 10.9348], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d15d50>\n",
      "Next token: tensor([29502, 29476,  1647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.6707, 12.7681, 12.0104, 11.3289, 11.1593], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b920>\n",
      "Next token: tensor([29502,  5486,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.4276, 10.8762, 10.7489, 10.6999, 10.0351], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28b80>\n",
      "Next token: tensor([29502, 29491,  2366], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.9054, 11.3709, 11.3602, 11.1856, 10.6765], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16430>\n",
      "Next token: tensor([29502,  1429,  3036], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.1242, 14.9788, 14.7867, 14.6529, 14.3255], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12980>\n",
      "Next token: tensor([29502,  1117,  1065], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.5624, 11.9249, 11.4833, 11.2408, 11.1140], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14a90>\n",
      "Next token: tensor([29502,  1032,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.8984, 12.1625, 11.6040, 11.0249, 10.8291], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12070>\n",
      "Next token: tensor([29502,  1235,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.4422, 14.1018, 11.4546, 11.1758, 10.9725], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28040>\n",
      "Next token: tensor([29502,  1094,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.5097, 14.5975, 14.5633, 13.1487, 12.1240], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16480>\n",
      "Next token: tensor([29502,  1114, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.9667, 13.1922, 12.9391, 12.7842, 12.5016], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16430>\n",
      "Next token: tensor([29502,  3510,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.1347, 11.0042, 10.5455, 10.4031, 10.3232], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b2e0>\n",
      "Next token: tensor([29502,  1315,  1647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.2828, 12.3237, 12.1391, 11.9453, 11.7282], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a122f0>\n",
      "Next token: tensor([29502,  1093,  3893], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.1274, 13.0655, 12.4885, 12.2417, 11.6521], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d175b0>\n",
      "Next token: tensor([29502, 29490,  1163], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.2350, 11.7204, 10.7959, 10.4755, 10.0840], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a104a0>\n",
      "Next token: tensor([29502,  1038,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.2694, 10.7649, 10.7210, 10.5430, 10.0355], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d151c0>\n",
      "Next token: tensor([29502, 29499, 18714], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([22.0525, 16.3168, 13.9135, 10.5938, 10.0711], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11cb0>\n",
      "Next token: tensor([29502,  1137,  3162], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.0640, 12.4203, 11.3752, 11.2181, 11.1881], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11120>\n",
      "Next token: tensor([29502,  1117,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.8255, 13.5654, 12.5912, 11.9314, 10.5947], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17a10>\n",
      "Next token: tensor([29502,  1032,  7127], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.8466, 16.4362, 14.7657, 10.6159, 10.1664], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a128e0>\n",
      "Next token: tensor([29502,  3782, 24937], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.9326, 14.9772, 14.0157, 13.6986, 13.1555], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17f60>\n",
      "Next token: tensor([29502,  3600,  1158], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.3073, 15.4937, 15.1769, 13.4220, 12.9668], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45030>\n",
      "Next token: tensor([29502,  1070,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.8447, 14.5257, 14.0852, 13.2930, 12.7922], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11ee0>\n",
      "Next token: tensor([29502,  5527, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.3109, 13.5007, 13.4627, 12.8561, 11.3965], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14a90>\n",
      "Next token: tensor([29502, 29501, 29538], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8188, 13.7088, 12.7371, 12.0240, 11.8183], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12700>\n",
      "Next token: tensor([29502, 29479, 29555], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.8268, 15.1871, 10.8467, 10.3947, 10.0742], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a299e0>\n",
      "Next token: tensor([29502,  1191,  1130], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.5620, 15.9605, 13.9713, 12.6450, 11.8983], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11c10>\n",
      "Next token: tensor([29502,  6364,  5888], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.7479, 15.5193, 14.9516, 14.7645, 12.8941], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17830>\n",
      "Next token: tensor([29502,  7138,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.3881, 13.3202, 13.2555, 12.4416, 10.7569], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a122f0>\n",
      "Next token: tensor([29502,  1652,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.2455, 14.3340, 13.5261, 13.5218, 12.9932], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  1951,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.5017, 12.5293, 12.3846, 11.7261, 11.3674], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16cf0>\n",
      "Next token: tensor([29502,  3066,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.0207, 15.2895, 14.6980, 13.8293, 12.4198], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11f30>\n",
      "Next token: tensor([29502,  1072, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.6282, 13.2781, 13.1895, 13.1692, 12.6408], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44680>\n",
      "Next token: tensor([29502, 12549,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.7113, 11.2547, 10.7393, 10.5801,  9.6420], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11bc0>\n",
      "Next token: tensor([29502,  1082,  1647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.6094, 13.9900, 13.8725, 12.7960, 12.7365], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14a90>\n",
      "Next token: tensor([29502,  1894,  7822], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.0507, 13.2331, 13.1892, 13.0000, 12.0531], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12070>\n",
      "Next token: tensor([29502, 29491,  1163], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.2495, 11.6184, 11.6056, 11.1576, 11.0385], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14630>\n",
      "Next token: tensor([29502,  1429,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.3118, 11.5494, 10.2810, 10.2681, 10.1206], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a127a0>\n",
      "Next token: tensor([29502,  1117,  1675], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.7769, 12.5971, 12.3858, 12.1888, 11.5070], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17010>\n",
      "Next token: tensor([29502,  1032, 18767], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.1758,  9.9528,  9.7350,  9.4201,  9.2463], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47e20>\n",
      "Next token: tensor([29502,  4997,  1051], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.7341, 12.9915, 11.9860, 11.7980, 11.1829], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16430>\n",
      "Next token: tensor([29502, 18029, 15146], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.6155, 14.0501, 13.8477, 13.6954, 13.3007], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a128e0>\n",
      "Next token: tensor([29502,  1092,  1254], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.9765, 13.9931, 13.7818, 13.0340, 13.0029], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d162f0>\n",
      "Next token: tensor([29502,  4792, 11357], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.9438, 14.9055, 14.0713, 13.2618, 12.7342], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a127a0>\n",
      "Next token: tensor([29502,  1137, 29493], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.3187, 11.6868, 11.5293, 11.3376, 11.3216], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d17560>\n",
      "Next token: tensor([29502,  1117,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.4111, 11.2657,  9.7637,  9.7193,  9.5206], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b290>\n",
      "Next token: tensor([29502,  2075,  1098], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.3556, 10.1184,  8.2120,  8.0902,  7.8655], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16570>\n",
      "Next token: tensor([29502,  1066,  4490], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([22.5703, 14.2155, 10.7661,  9.6624,  9.6457], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f740>\n",
      "Next token: tensor([29502,  3432,  1499], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.1671, 12.4331, 11.9271, 11.7730, 11.2156], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d14630>\n",
      "Next token: tensor([29502,  1037, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.4188, 12.6429, 12.1736, 10.9214, 10.6575], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47510>\n",
      "Next token: tensor([29502,  1072, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.1661, 13.5173, 10.5822, 10.2886,  9.9024], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a13f60>\n",
      "Next token: tensor([29502,  1347, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.5479, 13.0077, 12.3464, 11.6207, 11.5951], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d167f0>\n",
      "Next token: tensor([29502, 15971,  7791], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.7842, 14.3802, 12.8617, 12.8547, 11.8212], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a127a0>\n",
      "Next token: tensor([29502,  5527, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.1190, 13.2171, 13.1853, 12.1254, 11.9946], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a7a0>\n",
      "Next token: tensor([29502, 29491,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.0250, 11.5536, 11.5140, 10.8590, 10.6093], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16570>\n",
      "Next token: tensor([29502,   781,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.4757, 12.2305, 11.6316, 11.5310, 11.3056], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d760>\n",
      "Next token: tensor([29502,   781,  1782], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.3921, 10.6571, 10.2531, 10.1190,  9.7400], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a298a0>\n",
      "Next token: tensor([29502,  5621,  1647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.1870, 13.7909, 13.5245, 12.7677, 12.2588], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ade0>\n",
      "Next token: tensor([29502, 29476, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.0881, 12.9982, 10.9955, 10.6990, 10.2509], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([29502, 12256, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.7050, 10.9444, 10.9148, 10.8242, 10.4656], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2fd80>\n",
      "Next token: tensor([29502,  1117, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.2186, 14.1139, 12.4263, 11.3690, 11.0196], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1554e0b1da80>\n",
      "Next token: tensor([29502,  1032, 29552], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.6978, 15.9109, 13.9664, 13.1033, 12.8274], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a12070>\n",
      "Next token: tensor([29502,  4997, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.2111, 13.0838, 12.9287, 12.4670, 12.3850], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a29760>\n",
      "Next token: tensor([29502, 18029,  1171], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.8917, 12.8340, 12.6183, 12.0948, 11.0279], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5d16cf0>\n",
      "Next token: tensor([29502,  1092,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.9535, 11.8561, 11.8313, 11.1386, 10.8610], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11c10>\n",
      "Next token: tensor([29502,  4792,  1675], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.2307, 12.6175, 12.0211, 11.9289, 11.9012], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46020>\n",
      "Next token: tensor([29502,  1137,  1647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.3178, 13.3062, 12.5338, 11.7799, 11.3968], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11c10>\n",
      "Next token: tensor([29502,  1117,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.8538, 10.9264,  9.3093,  8.8216,  8.8123], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a295d0>\n",
      "Next token: tensor([29502,  2075,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.5386, 10.6649,  9.3950,  9.1959,  9.0523], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([29502,  1066, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.3524, 15.5781, 14.4811, 13.9290, 13.9255], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46930>\n",
      "Next token: tensor([29502,  3432, 29508], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.4794, 14.6002, 13.0362, 12.9109, 12.2791], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a11e40>\n",
      "Next token: tensor([29502,  1037, 29542], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.7912, 17.4553, 13.2201, 13.1045, 12.2223], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a7a0>\n",
      "Next token: tensor([29502,  1072, 29555], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.2382, 11.6355,  9.0455,  9.0257,  8.5328], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([29502,  1347, 29502], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.6930, 12.9785, 11.7390, 11.5282, 10.6164], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b2e0>\n",
      "Next token: tensor([29502, 15971, 29481], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.2633, 13.2357, 12.2866, 11.8734, 10.9750], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b2e0>\n",
      "Next token: tensor([29502,  5527, 13018], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.4100, 14.3078, 14.3033, 12.7640, 12.2788], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e020>\n",
      "Next token: tensor([29502, 29491, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.7340, 13.6144, 13.3490, 12.8428, 12.2058], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47010>\n",
      "Next token: tensor([29502,  1429,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.6507, 11.4922, 10.7657, 10.4727, 10.1834], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28db0>\n",
      "Next token: tensor([29502,  1117,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.0710, 11.7184, 11.5082, 11.4483, 11.2491], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([29502,  1032,  1832], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.5749, 12.1078, 11.9849, 11.3859, 11.0681], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2eed0>\n",
      "Next token: tensor([29502,  4997,  5392], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.8261, 14.6707, 13.4711, 11.9889, 11.9086], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e020>\n",
      "Next token: tensor([29502,  7138,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([22.3298, 12.6401, 12.4005, 10.9668, 10.6606], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28590>\n",
      "Next token: tensor([29502, 25849,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.0195, 13.6736, 13.2085, 12.3569, 12.0058], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a890>\n",
      "Next token: tensor([29502,  1245, 29501], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.9342, 13.7435, 11.9065, 11.8128, 11.7094], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  1040,  5392], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.1388, 11.0261, 10.6825, 10.6434, 10.5965], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a070>\n",
      "Next token: tensor([29502, 10014, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.7806, 17.6722, 15.7771, 15.4890, 15.2119], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  1070, 29518], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.5419, 12.2124, 12.0913, 11.7845, 11.3862], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b1a0>\n",
      "Next token: tensor([29502,  1040, 29502], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.4466, 13.2014, 12.7750, 11.9206, 10.9732], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  9391,  1532], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.0481, 12.4397, 11.5399, 11.3362, 11.2972], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a890>\n",
      "Next token: tensor([29502,  1398,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.8384, 10.6669, 10.0291,  9.8762,  9.7762], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a455d0>\n",
      "Next token: tensor([29502, 29476,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.5932, 14.4445, 13.6868, 11.6392, 11.5564], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45e90>\n",
      "Next token: tensor([29502,  5486,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([9.8961, 9.8331, 9.8239, 9.4436, 9.1222], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46250>\n",
      "Next token: tensor([29502, 29491,  2072], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.3960, 19.4871, 18.5047, 15.3949, 14.9152], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45e90>\n",
      "Next token: tensor([29502,  1429,  3318], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.7274, 13.1467, 12.3765, 11.2558, 10.0840], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44ae0>\n",
      "Next token: tensor([29502,  1117,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.9427, 11.1639, 10.7213, 10.5009,  9.9779], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  1032, 15235], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([23.9801, 13.9221, 13.8779, 12.9279, 12.7521], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28180>\n",
      "Next token: tensor([29502,  1235,  2540], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.4215, 13.7493, 11.6626, 11.3406,  9.9020], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2acf0>\n",
      "Next token: tensor([29502,  1094,  6858], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.4047, 14.0858, 13.6418, 13.1463, 12.6978], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a890>\n",
      "Next token: tensor([29502,  1114, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.2300, 12.6229, 12.2864, 10.9200, 10.8584], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e200>\n",
      "Next token: tensor([29502,  3510,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.2574, 17.2340, 12.7668, 12.5697, 10.6624], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28fe0>\n",
      "Next token: tensor([29502,  1315, 29501], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.6198, 12.4290, 11.6969, 10.8611, 10.7082], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c220>\n",
      "Next token: tensor([29502,  1093,  5392], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.8703, 12.9679, 10.7752, 10.7480,  9.9502], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f8d0>\n",
      "Next token: tensor([29502, 29490, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.2600, 17.6545, 14.4379, 12.3090, 12.0736], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a9d0>\n",
      "Next token: tensor([29502,  1038, 29518], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.1232, 16.8895, 16.4766, 16.1908, 15.9144], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45cb0>\n",
      "Next token: tensor([29502, 29499, 29538], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.9017, 13.0650, 12.4744, 12.2511, 11.1559], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a29f80>\n",
      "Next token: tensor([29502,  1137,  1532], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.4135, 12.0422, 11.1248, 11.0595, 11.0050], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a070>\n",
      "Next token: tensor([29502,  1117,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.5392, 10.2975, 10.1875,  9.5858,  9.2637], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b510>\n",
      "Next token: tensor([29502,  1032,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.9612, 14.8188, 14.3680, 11.9752, 11.6087], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47560>\n",
      "Next token: tensor([29502,  3782,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.2554,  9.9996,  9.7863,  9.7263,  9.6680], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a29760>\n",
      "Next token: tensor([29502,  3600, 15655], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.2230, 12.9736, 10.2199,  9.4822,  8.9065], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45120>\n",
      "Next token: tensor([29502,  1070,  7692], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.5363, 11.9206, 11.2400, 11.1515, 10.9147], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28ea0>\n",
      "Next token: tensor([29502,  5527,  6647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.2267, 13.1433, 11.9508, 11.6504, 11.6038], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a447c0>\n",
      "Next token: tensor([29502, 29501,  1065], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.9298, 11.3077,  9.9196,  9.0595,  8.4590], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ed90>\n",
      "Next token: tensor([29502, 29479,  1088], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.3595, 11.9719, 11.7523, 11.3201, 10.4665], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28090>\n",
      "Next token: tensor([29502,  1191,  1423], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.6927, 12.5303, 11.9894, 11.0480, 10.6003], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f970>\n",
      "Next token: tensor([29502,  6364,  1031], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.7812, 14.6118, 11.7853, 11.2768, 11.2400], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a444a0>\n",
      "Next token: tensor([29502,  7138,  1131], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.5843, 15.4447, 10.0577,  9.6164,  9.1777], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a444f0>\n",
      "Next token: tensor([29502,  1652, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.4196, 11.9748, 11.8399, 11.2745,  9.9781], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a477e0>\n",
      "Next token: tensor([29502,  1951,  3303], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8544, 13.4301, 13.2301, 10.0391,  9.8766], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a444f0>\n",
      "Next token: tensor([29502,  3066,  7653], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([24.2527, 15.8418, 15.1431, 12.7875, 12.7504], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2a9d0>\n",
      "Next token: tensor([29502,  1072,  2071], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.7219, 13.9528, 12.8238, 12.4112, 10.6739], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a298a0>\n",
      "Next token: tensor([29502, 12549, 21147], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.1822, 15.3825, 10.3709, 10.3240,  9.9321], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a294e0>\n",
      "Next token: tensor([29502,  1082, 11795], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.1840, 14.0910, 11.8711, 11.4489, 10.3060], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b060>\n",
      "Next token: tensor([29502,  1894,  4996], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.7914, 13.2036, 12.1967, 11.0170, 10.6903], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a294e0>\n",
      "Next token: tensor([29502, 29491,  8975], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.7708, 13.4984, 12.0189, 11.7849, 11.2420], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a28860>\n",
      "Next token: tensor([29502,   781,  1137], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.4054, 11.6886, 11.2312, 11.1015, 10.9629], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2fab0>\n",
      "Next token: tensor([29502,   781,  4335], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.4737, 14.3963, 14.1095, 12.7735, 12.3470], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d8f0>\n",
      "Next token: tensor([29502,  5621,  1279], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.4991, 15.8282, 12.2360, 11.2930, 11.2622], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a295d0>\n",
      "Next token: tensor([29502, 29476,  1227], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.2413, 16.1129, 15.9493, 14.4694, 13.8168], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a29b20>\n",
      "Next token: tensor([29502, 12256,  1113], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.1724, 13.2548, 12.7110, 12.0125, 11.4661], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2b060>\n",
      "Next token: tensor([29502,  1117, 29481], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([22.4067, 12.6808, 10.9669, 10.2648, 10.1508], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46a20>\n",
      "Next token: tensor([29502,  1032,  1655], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.3214, 13.8564, 13.0949, 11.3883, 11.3014], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46ed0>\n",
      "Next token: tensor([29502,  4997,  1420], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.9885, 12.6313, 12.1547, 12.1135, 11.7641], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44ae0>\n",
      "Next token: tensor([29502, 18029, 26681], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.9321, 15.0781, 11.4578, 10.2573,  9.7512], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a298a0>\n",
      "Next token: tensor([29502,  1092,  5263], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.5122, 15.9153, 13.3548, 13.3409, 12.4887], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44ae0>\n",
      "Next token: tensor([29502,  4792,  1066], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.1984, 14.1316, 13.6196, 12.7612, 11.2361], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47920>\n",
      "Next token: tensor([29502,  1137,  9235], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.1614, 11.9288, 10.9287, 10.2391,  9.6668], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46ed0>\n",
      "Next token: tensor([29502,  1117,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.6404, 14.3702, 10.2767,  9.7590,  9.6774], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45990>\n",
      "Next token: tensor([29502,  2075,  9434], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.9023, 15.3634, 14.8445, 13.2679, 12.0923], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a471f0>\n",
      "Next token: tensor([29502,  1066,  1210], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.1525, 12.5954, 12.5741, 12.2578, 11.5992], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ddf0>\n",
      "Next token: tensor([29502,  3432,  6550], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.8152, 14.0866, 12.9670, 11.6597, 11.2046], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2dda0>\n",
      "Next token: tensor([29502,  1037,  1206], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8473, 13.8897,  9.8060,  9.7052,  9.4055], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47560>\n",
      "Next token: tensor([29502,  1072,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.2375, 10.3894, 10.1655,  9.5326,  8.8984], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46b60>\n",
      "Next token: tensor([29502,  1347,  2820], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.1929, 17.1670, 13.4003, 12.5013, 11.8145], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44db0>\n",
      "Next token: tensor([29502, 15971,  6954], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.5231, 15.9796, 13.4455, 11.4420, 11.2782], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f970>\n",
      "Next token: tensor([29502,  5527, 10630], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.8917, 18.3997, 16.4792, 15.9536, 15.7179], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d760>\n",
      "Next token: tensor([29502, 29491,  1379], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.6261, 12.5771, 12.5016, 12.1357, 10.9145], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46020>\n",
      "Next token: tensor([29502,  1429,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.8290, 17.4660, 13.1144, 12.4469, 10.7101], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d6c0>\n",
      "Next token: tensor([29502,  1117, 29501], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.1665, 12.4212, 11.7021, 10.8576, 10.7323], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45e40>\n",
      "Next token: tensor([29502,  1032,  5392], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.3575, 12.7838, 10.4552, 10.4052, 10.1111], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44400>\n",
      "Next token: tensor([29502,  4997, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.0297, 18.3062, 13.7986, 12.1203, 11.5753], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c450>\n",
      "Next token: tensor([29502,  7138, 29518], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.3353, 17.0403, 16.9728, 16.9609, 16.1772], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ede0>\n",
      "Next token: tensor([29502, 25849, 29549], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.1545, 13.1341, 13.0574, 12.7335, 11.1441], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f970>\n",
      "Next token: tensor([29502,  1245,  1532], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.3653, 12.0913, 10.7078, 10.5606, 10.5468], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d800>\n",
      "Next token: tensor([29502,  1040,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.9007, 10.3004, 10.1258,  9.5839,  9.2922], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46e80>\n",
      "Next token: tensor([29502, 10014,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.5546, 14.5375, 14.3744, 11.6754, 11.3215], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45580>\n",
      "Next token: tensor([29502,  1070,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.7122, 10.0603,  9.9667,  9.6803,  9.6115], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ffb0>\n",
      "Next token: tensor([29502,  1040, 15655], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8681, 13.2178, 10.6668,  9.9927,  8.9925], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47970>\n",
      "Next token: tensor([29502,  9391,  7692], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.4978, 11.9633, 11.5135, 11.4753, 11.4331], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45990>\n",
      "Next token: tensor([29502,  1398,  6647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.7944, 13.8886, 12.2648, 12.0843, 11.6396], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44400>\n",
      "Next token: tensor([29502, 29476,  1065], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.1361,  9.8108,  9.4855,  9.0667,  8.8719], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46b60>\n",
      "Next token: tensor([29502,  5486, 20573], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.0683, 11.3955, 10.9836,  9.3970,  8.7439], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e890>\n",
      "Next token: tensor([29502, 29491,  1131], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.6354, 13.6237, 10.8212,  9.6492,  9.2873], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f970>\n",
      "Next token: tensor([29502,  1429, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.0523, 15.6320, 13.2907, 12.2198, 10.2033], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45b70>\n",
      "Next token: tensor([29502,  1117, 13956], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.7682, 13.1977, 12.1219, 11.3213, 11.2817], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2d6c0>\n",
      "Next token: tensor([29502,  1032,  1137], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.5507, 11.2269, 11.1650, 10.7159, 10.2972], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ee80>\n",
      "Next token: tensor([29502,  1235,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.5098, 11.4271, 11.3875, 11.1741, 10.3777], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e2a0>\n",
      "Next token: tensor([29502,  1094, 16083], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.9814, 13.6629, 10.9460, 10.7156, 10.1779], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a447c0>\n",
      "Next token: tensor([29502,  1114, 18917], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.7296, 13.0427, 12.9560, 12.8799, 12.7349], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45990>\n",
      "Next token: tensor([29502,  3510,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.2718, 12.4795, 11.1043, 10.9560, 10.6753], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44860>\n",
      "Next token: tensor([29502,  1315, 17270], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.2033, 19.0056, 14.5532, 13.2631, 11.3503], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a280e0>\n",
      "Next token: tensor([29502,  1093,  2628], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.5337, 16.0084, 12.8756, 12.6863, 12.1554], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46250>\n",
      "Next token: tensor([29502, 29490,  4156], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.4968, 15.3843, 14.3063, 13.6367, 13.3310], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a440e0>\n",
      "Next token: tensor([29502,  1038,  1117], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.1958, 15.4690, 13.5457, 12.9226, 12.7681], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e020>\n",
      "Next token: tensor([29502, 29499,  1227], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.4562, 13.4118, 12.4684, 12.3936, 12.3933], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47790>\n",
      "Next token: tensor([29502,  1137,  1032], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.4609, 14.0830, 12.8960, 11.0704, 10.9216], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a445e0>\n",
      "Next token: tensor([29502,  1117, 10079], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.8018, 14.6423, 14.5336, 14.1830, 13.3281], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47790>\n",
      "Next token: tensor([29502,  1032, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.9397, 13.1003, 12.5878, 11.2852, 10.9430], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45990>\n",
      "Next token: tensor([29502,  3782,   781], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.2861, 17.2654, 11.2866, 11.2090,  9.9600], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2eed0>\n",
      "Next token: tensor([29502,  3600, 29501], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.5109, 12.9371, 12.2766, 10.9243, 10.7175], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f1f0>\n",
      "Next token: tensor([29502,  1070,  5392], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.4816, 13.2014, 10.7759, 10.7150, 10.3672], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c4f0>\n",
      "Next token: tensor([29502,  5527, 29473], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.6604, 18.3223, 13.4236, 11.8635, 11.3292], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46e30>\n",
      "Next token: tensor([29502, 29501, 29518], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.6097, 17.2976, 17.0965, 16.7724, 16.5934], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44770>\n",
      "Next token: tensor([29502, 29479, 29555], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([17.3081, 13.0725, 12.7787, 12.2631, 11.0014], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f5b0>\n",
      "Next token: tensor([29502,  1191,  1532], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.6932, 12.3960, 10.9174, 10.7584, 10.7257], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c540>\n",
      "Next token: tensor([29502,  6364,  1183], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.6089, 10.4267, 10.2350,  9.7098,  9.6270], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2cbd0>\n",
      "Next token: tensor([29502,  7138,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.7378, 14.0180, 13.9146, 10.7182, 10.6846], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46250>\n",
      "Next token: tensor([29502,  1652,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.4506, 10.5612,  9.8050,  9.6176,  9.4719], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44950>\n",
      "Next token: tensor([29502,  1951, 15655], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.2440, 13.2195, 10.6282, 10.2293,  9.2260], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44c20>\n",
      "Next token: tensor([29502,  3066,  7692], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.5839, 12.0836, 11.5268, 11.5219, 11.3835], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46070>\n",
      "Next token: tensor([29502,  1072,  6647], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.6537, 14.0671, 11.9568, 11.5770, 11.3383], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44860>\n",
      "Next token: tensor([29502, 12549,  1065], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([10.0593,  9.9637,  9.8245,  9.0172,  9.0106], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45990>\n",
      "Next token: tensor([29502,  1082,  3737], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8736, 12.9546, 11.8920, 11.7068, 11.6246], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f4c0>\n",
      "Next token: tensor([29502,  1894,  4311], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.1575, 11.7395, 11.2049, 10.7391, 10.5790], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f740>\n",
      "Next token: tensor([29502, 29491,  1131], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.1066,  9.6351,  9.5881,  9.4279,  9.2848], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c590>\n",
      "Next token: tensor([29502,   781, 29491], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.9259, 10.7908, 10.3073,  9.5963,  9.4945], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46660>\n",
      "Next token: tensor([29502,   781,  1219], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.8090, 14.0021, 12.2672, 11.9585, 11.8470], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2e5c0>\n",
      "Next token: tensor([29502,  5621, 29510], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([21.8017, 13.1347, 13.0203, 12.7829, 12.3750], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45030>\n",
      "Next token: tensor([29502, 29476, 29528], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8460, 13.8731, 12.4344, 11.6338, 11.4323], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44c20>\n",
      "Next token: tensor([29502, 12256, 21952], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.9822, 13.1654, 11.7667, 11.4262, 11.4176], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47290>\n",
      "Next token: tensor([29502,  1117,  1137], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.3992, 11.5980, 10.4674,  9.8644,  9.5762], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46b10>\n",
      "Next token: tensor([29502,  1032,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([11.9669, 11.2931, 11.2345, 10.6583, 10.6147], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a45850>\n",
      "Next token: tensor([29502,  4997,  3826], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([16.7978, 15.9851, 15.7535, 14.7622, 14.2864], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f100>\n",
      "Next token: tensor([29502, 18029,  1761], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.3882, 13.7804, 13.7285, 13.3838, 12.7307], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a464d0>\n",
      "Next token: tensor([29502,  1092,  1751], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([23.5469, 15.1586, 13.0013, 10.8193, 10.7254], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44a90>\n",
      "Next token: tensor([29502,  4792,  6980], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([12.7858, 12.4100, 11.8547, 11.6148, 11.2781], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46ed0>\n",
      "Next token: tensor([29502,  1137,  1040], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.8853, 12.1267, 11.6159, 11.1648, 11.1333], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2dfd0>\n",
      "Next token: tensor([29502,  1117,  1495], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.3729, 15.6737, 13.0291, 12.4439, 11.5480], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a47920>\n",
      "Next token: tensor([29502,  2075, 29493], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.6949, 16.2258, 13.5420, 11.0023, 10.4186], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2c400>\n",
      "Next token: tensor([29502,  1066,  2401], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([20.3280, 19.8649, 18.5585, 11.6252, 11.0927], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2cdb0>\n",
      "Next token: tensor([29502,  3432, 29493], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.8309, 18.5440, 14.5786, 10.3833,  9.9161], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2f3d0>\n",
      "Next token: tensor([29502,  1037,  1072], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([19.6652, 11.6388, 11.3448, 11.1368, 11.0179], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2ce00>\n",
      "Next token: tensor([29502,  1072,  9485], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([18.0493, 14.3295, 12.5838, 11.5559, 11.2490], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a2cf90>\n",
      "Next token: tensor([29502,  1347,  1070], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([13.6206, 13.2661, 12.5162, 11.8261, 11.7031], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a4f920>\n",
      "Next token: tensor([29502, 15971,  9434], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.1122, 14.5745, 13.4036, 13.2377, 13.2243], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a458f0>\n",
      "Next token: tensor([29502,  5527, 29493], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([15.7391, 13.6765, 13.1008, 13.0202, 12.8952], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a4e890>\n",
      "Next token: tensor([29502, 29491,  1330], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.9683, 14.6757, 13.1568, 13.0643, 12.6834], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a46ed0>\n",
      "Next token: tensor([29502,  1429,  1227], device='cuda:1')\n",
      "EOS ID: 2\n",
      "Last tok prelogits shape torch.Size([3, 32768])\n",
      "Top k prelogits: tensor([14.6026, 13.7994, 11.5130, 11.1504, 11.1485], device='cuda:1')\n",
      "Top k indices: <built-in method indices of Tensor object at 0x1550d5a44f40>\n",
      "Next token: tensor([29502,  1117,  1040], device='cuda:1')\n",
      "EOS ID: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mpipeline_args\u001b[38;5;241m.\u001b[39mw_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_pre_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconditioning\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_prefix_prompt\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBased on the context \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconditioning\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_post_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext_prompts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_prefix_prompt\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mno_context_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_conditioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconditioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate_double_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m generated_sequence:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(seq, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/llm_embed/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/augmented_model.py:712\u001b[0m, in \u001b[0;36mEmbedAugPipeline.generate_mistral\u001b[0;34m(self, text_conditioning, device, prompt_pre_embed, prompt_post_embed, max_tokens, temperature, truncate_line, device_generation, embed_seqlens, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchrun():\n\u001b[1;32m    709\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m--> 712\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmistral_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_pre_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_pre_embed_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_post_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_post_embed_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_att\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice_generation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_generation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_att\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membed_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcat_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_both\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_att\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat_embeddings\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m produced_text \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_tokens[i])\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(generated_tokens))\n\u001b[1;32m    737\u001b[0m ]\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m truncate_line:\n",
      "File \u001b[0;32m~/micromamba/envs/llm_embed/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/generate.py:148\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt_pre_embed, prompt_post_embed, model, max_tokens, temperature, chunk_size, embeddings, eos_id, embed_seqlens, cat_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     generated_tensors\u001b[38;5;241m.\u001b[39mappend(next_token[:, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m--> 148\u001b[0m     last_token_prelogits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcat_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_att_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_att_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_token_prelogits\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    159\u001b[0m         B,\n\u001b[1;32m    160\u001b[0m         V,\n\u001b[1;32m    161\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast token prelogit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_token_prelogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; B: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; V: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mV\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m generated_tokens: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/cross_att_transformer.py:923\u001b[0m, in \u001b[0;36mTransformer.generate\u001b[0;34m(self, input_ids, seqlens, embed_seqlens, embeddings, cache, cat_embeddings, cross_att_cache)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     cross_att_cache: CrossAttCache \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 923\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_att_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_att_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcat_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_rank \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pipeline_ranks \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# ignore the intermediate activations as we'll get the final output from\u001b[39;00m\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# the last stage\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         out_shape \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/cross_att_transformer.py:870\u001b[0m, in \u001b[0;36mTransformer.generate_partial\u001b[0;34m(self, input_ids, seqlens, embeddings, embed_seqlens, cache, cross_att_cache, cat_embeddings)\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    868\u001b[0m         xk, xv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 870\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_att_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_att_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_att_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqlens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    883\u001b[0m     h \u001b[38;5;241m=\u001b[39m layer(\n\u001b[1;32m    884\u001b[0m         x\u001b[38;5;241m=\u001b[39mh,\n\u001b[1;32m    885\u001b[0m         freqs_cis\u001b[38;5;241m=\u001b[39mfreqs_cis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    888\u001b[0m         seqlens\u001b[38;5;241m=\u001b[39mseqlens,\n\u001b[1;32m    889\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/llm_embed/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/llm_embed/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/embed_llm/embed_llm/models/mistral/cross_att_transformer.py:254\u001b[0m, in \u001b[0;36mCross_AttTransformerBlock.forward\u001b[0;34m(self, x, freqs_cis, xk, xv, cache, self_mask, cross_att_mask, show_attention, pool_att_embds, seqlens)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m xv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# print(\"xk and xv\", xk.shape, xv.shape)\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# print('STATS',torch.mean(xk), torch.mean(xv), torch.std(xk), torch.std(xv))\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# print(\"h\", h.shape)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m show_attention:\n\u001b[0;32m--> 254\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_att_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxv\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m         r, cross_attn_mtx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    259\u001b[0m             x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_norm(h),\n\u001b[1;32m    260\u001b[0m             mask\u001b[38;5;241m=\u001b[39mcross_att_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m             show_attention\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    264\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w_embeds = True\n",
    "temp = 0\n",
    "max_tokens = 256\n",
    "n_context = 0\n",
    "i_token_to_flip = -1\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "other_device = device if device_count <= 1 else torch.device(\"cuda:1\")\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "\n",
    "temp = [temp] * max_tokens   \n",
    "if max_tokens > i_token_to_flip >= 0:\n",
    "    temp[i_token_to_flip] = -1\n",
    "\n",
    "# 1 information in the doc which enables to answer the question but not good response often in-context\n",
    "# 2 information in the doc which enables to answer the question and good response often in-context\n",
    "# 3 Hard negative passage\n",
    "\n",
    "\n",
    "\n",
    "prompt_prefix = [\"Query: who wrote the song photograph by ringo starr\\nAnswer: Ringo Starr\\n\\n\",\"Query: who is playing the halftime show at super bowl 2016\\nAnswer: Coldplay\\n\\n\",\"Query: where was the world economic forum held this year\\nAnswer: Davos\\n\\n\",\"Query: where are the giant redwoods located in california\\nAnswer: Humboldt County\\n\\n\",\"Query: who has made the most premier league appearances\\nAnswer: Gareth Barry\\n\\n\"]\n",
    "prompt_prefix = ''.join(prompt_prefix[:n_context])\n",
    "# prompt_prefix = \"Query: \"\n",
    "\n",
    "# prompts = ['who has most followers on instagram in world','who did the united states win its independence from', 'what is the capital of France']\n",
    "prompts = [\"what is the hot coffee mod in san andreas\",\"who wrote he ain't heavy he's my brother lyrics\",\"when was the last time anyone was on the moon\"]\n",
    "context_prompts = [' answer the question following the examples ' +prompt_prefix + 'Query: '+ prompt  + '\\nAnswer:' for prompt in prompts]\n",
    "# no_context_prompts = [prompt_prefix + 'Query: '+ prompt + '\\nAnswer:' for prompt in prompts]\n",
    "no_context_prompts = ['' for prompt in prompts]\n",
    "\n",
    "# conditioning = [\"This list contains the top 50 accounts with the most followers on the photo and video-sharing social platform Instagram. As of July 2019, the most followed user is Instagram's own account, with over 308 million followers. Cristiano Ronaldo is the most followed individual, with over 177 million followers. Fifteen accounts have exceeded 100 million followers on the site.\",\n",
    "#                 \"During the American Revolution, the legal separation of the thirteen colonies from Great Britain in 1776 actually occurred on July 2, when the Second Continental Congress voted to approve a resolution of independence that had been proposed in June by Richard Henry Lee of Virginia declaring the United States independent from Great Britain's rule. After voting for independence, Congress turned its attention to the Declaration of Independence, a statement explaining this decision, which had been prepared by a Committee of Five, with Thomas Jefferson as its principal author. Congress debated and revised the wording of the Declaration, finally approving it two days later on July 4. A day earlier, John Adams had written to his wife Abigail\",\n",
    "#                 \"France is a country located primarily in Western Europe. Its overseas regions and territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean, giving it one of the largest discontiguous exclusive economic zones in the world. Metropolitan France shares borders with Belgium and Luxembourg to the north, Germany to the northeast, Switzerland to the east, Italy and Monaco to the southeast, Andorra and Spain to the south, and a maritime border with the United Kingdom to the northwest. Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea. \"]\n",
    "\n",
    "conditioning = ['Hot Coffee is a normally inaccessible mini-game in Grand Theft Auto: San Andreas. The mini-game portrays crudely animated sexual intercourse between the main character and a chosen partner. After Patrick Wildenborg, a software engineer who also went by the alias \\\"PatrickW\\\", modified the game to make the mini-game accessible, Hot Coffee quickly gained notoriety worldwide, impacting consumer culture, politics and the video game industry as a whole. Rockstar initially blamed a \\\"determined group of hackers\\\" for hacking the base game and creating the mini-game from scratch. This claim was eventually refuted, as the mini-game\\'s code and assets had been developed by Rockstar and were already present, unfinished and abandoned, on the game disc: the mod simply made the existing content available to players. Rockstar would go on to indicate that they expected the ESRB rating to remain unchanged, as they had no control',\n",
    "                \"He Ain't Heavy, He's My Brother written by Bob Russell and Bobby Scott; all other titles written by Neil Diamond.\",\n",
    "                \"17, 1970, as part of the Lunokhod program. To date, the last human to stand on the Moon was Eugene Cernan, who as part of the Apollo 17 mission, walked on the Moon in December 1972. Apollo 17 was followed by several uncrewed interplanetary missions operated by NASA. One of the notable interplanetary missions is Voyager 1, the first artificial object to leave our Solar System into interstellar space on August 25, 2012. It is also the most distant artificial object from Earth. The probe passed the heliopause at 121 AU to enter interstellar space. Voyager 1 is currently at a distance of 145.11 AU (21.708 billion kilometers; 13.489 billion miles) from Earth as of January 1, 2019.\"]\n",
    "\n",
    "# answers = ['Instagram','Great Britain',\"Paris\"]\n",
    "# answers = [\"a normally inaccessible mini-game\", [\"Bobby Scott\", \"Bob Russell\"],[\"14 December 1972 UTC\", \"December 1972\"]]\n",
    "\n",
    "# conditioning = 'Kyutai is a non-profit laboratory dedicated to open research in AI, founded in November 2023 by the iliad Group, CMA CGM and Schmidt Sciences.'\n",
    "# prompts =  prompt_prefix +'Query: when was founded Kyutai?\\nAnswer: '\n",
    "\n",
    "\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "\n",
    "generated_sequence = pipeline.generate(\n",
    "    prompt_pre_embed = (['']*len(conditioning) if not pipeline.pipeline_args.w_prefix_prompt \n",
    "    else ['Based on the context ']*len(conditioning)), \n",
    "    prompt_post_embed = context_prompts if pipeline.pipeline_args.w_prefix_prompt  else no_context_prompts,\n",
    "    text_conditioning=conditioning,\n",
    "    temperature=temp,\n",
    "    max_tokens=max_tokens,\n",
    "    truncate_double_space=True,\n",
    "    device=device,\n",
    "    device_generation=other_device,\n",
    ")\n",
    "\n",
    "for seq in generated_sequence:\n",
    "    print(seq, '\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_toks = pipeline.pipeline_args.max_seq_len\n",
    "\n",
    "atlas_eval_data = \"/lustre/scwpod02/client/kyutai-interns/hippop/processed_data/wiki_passages_pretraining/valid_atlas_enwiki-dec2021_standard.jsonl\"\n",
    "atlas_valid_passage = []\n",
    "dump_eval_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_valid.jsonl'\n",
    "dump_valid_passage = []\n",
    "\n",
    "with open(atlas_eval_data, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        atlas_valid_passage.append(\n",
    "            pipeline.tokenizer.decode(\n",
    "                pipeline.tokenizer.encode(\n",
    "                    json.loads(line)[\"text\"], eos=True, bos=True\n",
    "                )[:lim_toks]\n",
    "            )\n",
    "            )\n",
    "random.shuffle(atlas_valid_passage)\n",
    "\n",
    "\n",
    "with open(dump_eval_data, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        text = json.loads(line)[\"text\"]\n",
    "        dump_valid_passage.append(\n",
    "                pipeline.tokenizer.decode(\n",
    "                    pipeline.tokenizer.encode(\n",
    "                        text if \"\\n\\n\" not in   text else text.split(\"\\n\\n\")[1], eos=True, bos=True\n",
    "                    )[:lim_toks]\n",
    "                )\n",
    "            )\n",
    "random.shuffle(dump_valid_passage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_passages = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.0\n",
    "device_count = torch.cuda.device_count()\n",
    "other_device = device if device_count <= 1 else torch.device(\"cuda:1\")\n",
    "atlas_generated_sequences = []\n",
    "for i in range(0, n_passages, max_batch_size):\n",
    "    passage = atlas_valid_passage[i : i + max_batch_size]\n",
    "    generated_sequence, logprobs = pipeline.generate(\n",
    "        prompt_pre_embed = (['']*len(passage) if not pipeline.pipeline_args.w_prefix_prompt \n",
    "        else ['In other words, background: ']*len(passage)), \n",
    "        prompt_post_embed = (['']*len(passage) if not pipeline.pipeline_args.w_prefix_prompt \n",
    "        else [' is just another way of saying: ']*len(passage)),\n",
    "        text_conditioning=passage,\n",
    "        temperature=temp,\n",
    "        max_tokens=lim_toks,\n",
    "        truncate_double_space=False,\n",
    "        device=device,\n",
    "        device_generation=other_device,\n",
    "    )\n",
    "\n",
    "    atlas_generated_sequences.extend(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.0\n",
    "device_count = torch.cuda.device_count()\n",
    "other_device = device if device_count <= 1 else torch.device(\"cuda:1\")\n",
    "dump_generated_sequences = []\n",
    "for i in range(0, n_passages, max_batch_size):\n",
    "    passage = dump_valid_passage[i : i + max_batch_size]\n",
    "    generated_sequence, logprobs = pipeline.generate(\n",
    "        prompt_pre_embed = (['']*len(passage) if not pipeline.pipeline_args.w_prefix_prompt \n",
    "        else ['In other words, background: ']*len(passage)), \n",
    "        prompt_post_embed = (['']*len(passage) if not pipeline.pipeline_args.w_prefix_prompt \n",
    "        else [' is just another way of saying: ']*len(passage)),\n",
    "        text_conditioning=passage,\n",
    "        temperature=temp,\n",
    "        max_tokens=lim_toks,\n",
    "        truncate_double_space=False,\n",
    "        device=device,\n",
    "        device_generation=other_device,\n",
    "    )\n",
    "\n",
    "    dump_generated_sequences.extend(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG scores 0.8125772827951994\n",
      "AVG scores TRUNC 0.8183385157580503\n",
      "Very small bleu 1\n",
      "Mismatch 31\n"
     ]
    }
   ],
   "source": [
    "avg_bleu = 0\n",
    "n_mismatch = 0\n",
    "n_very_small_blue = 0\n",
    "for gen, gt in zip(dump_generated_sequences, dump_valid_passage):\n",
    "    bleu_score = get_bleu_score(gt, gen)\n",
    "    avg_bleu += bleu_score\n",
    "    \n",
    "    try:\n",
    "        if bleu_score != get_bleu_score(gt, gen, trunc = True):\n",
    "            n_mismatch += 1\n",
    "            # print('MISMATCH {}'.format(n_mismatch))\n",
    "            # print('Ge:', gen)\n",
    "            # print('GT:', gt)\n",
    "            # print(bleu_score, ' | ', get_bleu_score(gt, gen, trunc = True))\n",
    "            if bleu_score < 0.1:\n",
    "                n_very_small_blue += 1\n",
    "            \n",
    "        elif bleu_score < 0.1:\n",
    "            n_very_small_blue += 1\n",
    "            print('VERY SMALL BLEU {}'.format(n_very_small_blue))\n",
    "            print('Ge:', gen)\n",
    "            print('GT:', gt)\n",
    "            print(bleu_score)\n",
    "    except ValueError:\n",
    "        print('Passages skipped')\n",
    "\n",
    "print('AVG scores',get_bleu_score(dump_valid_passage, dump_generated_sequences))\n",
    "print('AVG scores TRUNC',get_bleu_score(dump_valid_passage, dump_generated_sequences, trunc = True))\n",
    "print('Very small bleu', n_very_small_blue)\n",
    "print('Mismatch', n_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERY SMALL BLEU 1\n",
      "Ge: 0 A subsequence of a string whose characters are common in two strings (S1 and S2) can be computed efficiently using the notion of common subsequence. The problem has a simple algorithmic solution; both standard algorithms run in linear time in DSPSS (this is still faster than in Python) for a computer. It has been well studied in mathematics, its basic notions of deletions and appearances, the problem of finding Maximal Common Subsequences for sequences of four or more characters, for extra characters with few constraints that have the property of overlapping in more than one way. This problem (and its generalization to image alignment and image reconstruction) fits in studies of the geometry of editing theories (in Russian), dynamical systems, and computer science, and is motivated by the mean comparison of DNA sequences and the reconstruction of common subsequences at short edit distances. If one computes long subsequences of S1 and S2, such that the computations on such subsequences would not be revised by chance if they were returned from a computer. What one gets from this computation is a relation that is evidently useful to calculate the global similarity, not particularly biological or mathematical.\n",
      "GT:  A common subsequence of two strings S and T is a string whose characters appear in the same order (not necessarily consecutively) both in S and in T. The problem of computing a longest common subsequence has been well studied in computer science. It can be solved in polynomial time by dynamic programming; this basic algorithm has additional speedups for small alphabets (the Method of Four Russians), for strings with few differences, for strings with few matching pairs of characters, etc. This problem and its generalizations to more complex forms of edit distance have important applications in areas that include bioinformatics (in the comparison of DNA and protein sequences and the reconstruction of evolutionary trees), geology (in stratigraphy), and computer science (in data comparison and revision control). One motivation for studying the longest common subsequences of random strings, given already by Chvátal and Sankoff, is to calibrate the computations of longest common subsequences on strings that are not random. If such a computation returns a subsequence that is significantly longer than what would be obtained at random, one might infer from this result that the match is meaningful or significant.\n",
      "0.09710923867339806\n",
      "VERY SMALL BLEU 3\n",
      "Ge: Zapp brought the bones of this thing out into the world. \"All I say,\" says a documentary film, in which they made sure you were a track which really does sound exactly like Real Tunes. For the first time on record, Fender Rhodes can hear them - fanatic with a giant, tenth-tall way!\" and the fans decided on Grand Funk III to split up again only 4 days after they overdubbed their voices. All Zapp stayed until summer of 1985, trying to talk him out of it, although the album wasn't an 'unqualified success' in the US. The album became the first topping both releases to Billboard Top 200 Melter.\"\n",
      "GT:  bring the balls out of this thing.\" Zappa said, \"All I did was, in a documentary way, make a record which tells you exactly what they really sound like. For the first time on record you can hear Grand Funk Railroad ... and they're fantastic, fan-tastic with an F three times taller than you!\" Grand Funk decided on the first day of overdubs to split up again, although Zappa stayed until 4 a.m. trying to talk them out of it. The album wasn't a commercial success, only making it to #52 in the Billboard Top 200''. The album was the final release to feature both bassist Mel Schacher and keyboardist Craig Frost.\n",
      "0.09549153712369463\n",
      "VERY SMALL BLEU 4\n",
      "Ge: Bordeaux, most inland wines are serious bottles, although undergoing an ageing-process. Sometimes, white wine can be an exception in Bordeaux. The must of château-barrel ageing requires 6 barrels of must for each, but some new châteaux (which number as high as 20 meters above the oak barrel) can impart a different degree of ageing. Just recently, the volume of wine to be added to Bordeaux is heritage-protected. In order to make barrel ageing, the châteaux have to be racked from time to time in clear mold. This process is attacked by living organisms, as recently as itmakes sense since adding the châteaux to the blend can also be done. Additionally, periods of ageing es.eseseseseseseseses\n",
      "GT:  In Bordeaux, most serious wines undergo barrel-ageing, although white wines can be an exception. Usually, six months of ageing in-barrel is required, but some châteaux barrel-age for as much as 20 months. The number of new barrels (which impart a higher degree of oak flavor to the wine) can vary from vintage to vintage, just as the duration of barrel-ageing. Only recently, addition of oak chips has been made legal in Bordeaux. During barrel-ageing, the wine needs to be racked in order to clear it of lees. This process is being challenged by some producers, as mentioned abovem since ageing on the lees can also add richness to the wine.\n",
      "0.0\n",
      "VERY SMALL BLEU 5\n",
      "Ge: Mr. Critical was mostly positive review of both Monroe's resurrection, with fellow reviewers highlighting Wells's development of the character. Aviation Monthly's Jonathan Keller praised Monroe's complementary plotting as a \"clever balance between Savage and Wells for a piece of fiction\". Paul Nardini stated that Superman Had to Have Murdered Himself had never altered his own blog, saying: \"If I hadn't told my series intro earlier, I'd also be looking askance at the latter's failure to continue from the book\". Amazon.com commended Monroe's plotting as a \"strong counterpoint to any implications of the original story\", whereas Kenneth Beggs of Family Friendly Gaming described the book's \"realistic aspects\" and \"friendship with the main characters\". Keeping the vital fictional elements of the tale offers that the series addresses a \"nasty, chilling, and bloody mash-up of vampires and zombies\" with \"punctuated dialogue\". Audiences Magazine praised the book for its suitability for schoolchildren. Starfleet.com wrote, \"Monroe is a smart, powerful plotline while\n",
      "GT:  Critical reception of Mr. Monster was mostly positive, with multiple reviewers highlighting Wells's further development of both the protagonist and plot. A Savannah Morning News review complimented John Cleaver's characterization as \"a nifty balancing act for Wells to have pulled off\". Lee Mandelo praised Wells's expansion of Serial Killer into a series, stating: \"If his own blog hadn't told me otherwise, I would never have guessed he hadn't intended a sequel from the beginning\". Alternative Magazine also commended Wells's continuation of the storyline, saying that Mr. Monster \"immediately addresses any faults with its predecessor's ending\" while keeping the \"strong aspects of the original story\". Kirkus Reviews noted that \"John's realistic familial relationships and friendships offer a counterbalance to the bloody, fantastical elements of the tale\" and recommended the novel for \"fans of genre mash-ups\". A School Library Journal reviewer described Mr. Monster as \"compelling, quick-paced, and chilling\". Publishers Weekly wrote that the book \"stands out with taut, sharp writing, strong plotting,\n",
      "0.0\n",
      "Passages skipped\n",
      "Passages skipped\n",
      "VERY SMALL BLEU 7\n",
      "Ge: London-Smiths Blacksmiths, except backyard enterprises - Craftsmen chose blacksmiths to provide transportation, abbreviated trolley, and horse carriage shops. ; The Concert Hall that served as an entertainment venue for 1840s to 1884 was the first operating theatre in the area. ; Foresight Tavern - This community-owned tavern established the London Correspondence Lodges and provided meeting places for local freemasons like their masters. ; Mullet Lodge was constructed in Phase I. Powerful London St. Andrews Methodist Church buildings are similar to what could be found in the early 19th century when the first horse drawn trolley arrived from an Irish settlement. These included resort municipalities with orange hues like Orangeville, Ontario. Built in the area of the settlement where the townships of Huron also fanned out, many builders were establishing a reputation for themselves in the region, bringing a need for paved roads through the village. The community was representative of early London's streets, docks, lakes and canals. ; Concert Hall when it came to a decision to construct a traveling house for the town\n",
      "GT: Blacksmith Shop-Entrepreneurs, like blacksmiths, chose transportation crossroads to establish off-farm businesses. ; Corbett Tavern - An 1840s tavern that provided accommodation, food and stabling for horses to the traveling public and served as the community meeting place. ; Lochaber Church - This Free Presbyterian Church was constructed in 1884. ; Mount Moriah Lodge - Masonic orders held their first meetings in local taverns until purpose built halls like this one could be constructed. The interior is representative of an early 19th-century London Masonic Hall. ; Purple Hill Lodge - Established by the Protestant Irish immigrants who brought Orangeism with them when they came to Canada. Many settled areas in the region of what is now southwestern Ontario built meeting halls for the orange order, including townships in the London district. These buildings were also a focal point for the community, providing a place where settlers could get to know their neighbors through dances, dinners, recitals and concerts. Representative of the first stage of urban development at a transportation crossroads. \n",
      "0.0\n",
      "VERY SMALL BLEU 8\n",
      "Ge: Perry Botkin: Special effects, piano, lead guitar ; Mainly Joe Harnell: Piano, RCA Studio Orchestra ; David Levine: Guitar, Tom Ferguson: Guitar, Mike Reeves: Corrado. ; strings: Jesse Levy, Ben Cohen, Neil Stubenhaus, Bruce Ditmas, Pete Jolly, Sol Infante ; guitar: Izzy Sherr ; percussion: Grover Washington, Jr., Paul Enger, Jerry Zenkin, Harvie Swartz, Fred Seibert, David Laub, Amy Assante, Sahib Shihab, Joe Napolitano, Terry Nuttycombe, Rene Vinyl ; cellos: Allan Shrock, Ervin Roth ; strings: Kermit Moore, Bill Green, Gerald Friedman ; guitar: Hank Cicalo, Buddy Rich, Tony Levin, Getty Peterson, Gayle Levant, Blossom Allen, John Word ; flutes: Buddy Rich, Chuck Rainey, Bruce Barth ; flutes: Jim Peterson, CAPA, Seymour Barab ; contractor: Leo S. Brubaker ; father: George Palmer \n",
      "GT: Special effects: Perry Botkin, Jr. ; Piano: Tom Hensley, Mike Lang, Pete Jolly ; Guitar: Lee Ritenour, David Cohen, Neil Levang ; Bass: Max Bennett, Reinie Press, Steve LaFever ; drums: Joe Correro, Sol Gubin ; percussion: Gene Estes ; violins: Iz Baker, Paul Shure, Jerry Vinci, Sid Sharp, Tibor Zelig, Henry Ferber, Assa Drori, Jimmie Getzoff, Harry Bluestone, Erno Neufeld, Nate Ross ; violas: Dave Schwartz, Allan Harshman, Gerry Nuttycombe, Sven Reher ; cellos: Ray Kramer, Fred Seykora, Armand Kaproff ; woodwinds: Johnny Rotella, Gene Cipriano, Ronnie Lang, Bud Shank, Bill Green ; Harp: Gayle Levant ; trumpets: Bill Peterson, Bud Brisbois, Tony Terran, Cappy Lewis, Buddy Childers ; trombones: Charles Loper, Dick Nash ; Musical contractor: Charles H. Stern ; Engine\n",
      "0.0\n",
      "VERY SMALL BLEU 11\n",
      "Ge: volcanic vents to the East covered the area, and a fault trench formed during the eastward slope of the Fissure. The east side of the Fissure opens the valley of the Lander River, and the north side is the range, which was filled with diorite, while the hooping vents filled with porphyry. The fault trench composes these faults into \"mineral-bearing \"ore\". The faults called \"mineral ore\" stated that \"pockets are abundant\". The miners made the ore widely through the thin black slate of the East Fissure and nearly all their upper layer in \"like a charity case\", although only parts of the upper and lower layers were found or plowed. With them the fault trench extended in all directions, and \"rich sextuple ore\" was almost 600 ft wide.\n",
      "GT:  Volcanic vents to the east covered the area during the Tertiary, and a fault fissure opened the east slope of the Virginia Range. The east slope of the range forms the footwall of the Lode, and is composed of diorite, while the hanging wall is composed of andesite, which the miners called \"porphyry\". The fault fissures filled these fissures with \"mineral-bearing quartz\". The miners stated \"porphyry makes ore\". The ore bodies were thinly scattered through the wide Lode \"like plums in a charity pudding\", and nearly all of them were found in the wide upper section and along or near the east wall. Although the miners extended their work in all directions, only \"sixteen large and rich ore bodies\" were found, most less than 600 ft in depth.\n",
      "0.0\n",
      "VERY SMALL BLEU 12\n",
      "Ge: 6th from the Events in Ireland.............\n",
      "GT:  Events from the 6th century in Ireland.\n",
      "0.0\n",
      "VERY SMALL BLEU 13\n",
      "Ge: Halichard 4, Jens Kehrle 4, Hans Kuys 3, Asitsholts 3, Volodymyr Kolodzey 3. AAU Amsterdam, Netherlands: Amsterdam Arena, April 17-19, 1976 – UEFA National Final in Amsterdam 101:108 (wellmans in favour of VALL 59-79) Jens Kehrle:- 84, Steve Grazier, Bryce Wells, Frank Maravitch, Vivian Horton, Tucker Smith. 3rd All Star All-Star Week 1978-79 AAU Amsterdam, Netherlands: Universe 25-39 (Nag 15-21) IN: Hans Peters, Bill Croft, Gary Fenn, Dirk Hagens (16), John Lee 20-23, Steve Grazier 20-23, Emmett Ford 16-47, John Hankma, Pete Mildenhall, Everett Dawson, Carl Krapp: 131 Jopal Zone. N 2-1 (238).\n",
      "GT:  Heidrich 4, Hans Kaltschmidt 4, Jürgen Kolze 4, Volker Asshoff 3. Apollohal, Amsterdam, April 17, 1976: USA All Stars in Netherlands – USA All Stars in West Germany 109-89 (att:51-39) USA All Stars in Netherlands : Owen Wells, Steven Bravard, Gary Freeman, Vince Fritz, Tyrone Marioneaux, Buff Kirkland, Hank Smith. 5th All-Star Gala 1977-78 Apollohal, Amsterdam, April 23, 1978: North – South 158-165 NORTH (Jim Parks): Al Davis 33, Dan Henderson 21, Pete Miller 20, John Franken 20, Hank Smith 18, Gary Freeman 16, Everett Fopma 13, John Wayne Croft 9, Emill Hagens 7, Bert Kragtwijk 1. SOUTH (Manny Cramford): Billy Taylor 2\n",
      "0.0\n",
      "Error with update: \n",
      "Ground-Truth:  Untung Pakai Esia  \n",
      "Pred:  untuk Pangai Esia   \n",
      "AVG scores 0.41971318539118835\n",
      "Error with update: \n",
      "Ground-Truth:  Untung Pakai Esia  \n",
      "Pred:  untuk Pangai Esia \n",
      "AVG scores TRUNC 0.43351392936413774\n",
      "Very small bleu 13\n",
      "Mismatch 50\n"
     ]
    }
   ],
   "source": [
    "avg_bleu = 0\n",
    "n_mismatch = 0\n",
    "n_very_small_blue = 0\n",
    "for gen, gt in zip(atlas_generated_sequences, atlas_valid_passage):\n",
    "    try:\n",
    "        bleu_score = get_bleu_score(gt, gen)\n",
    "        avg_bleu += bleu_score\n",
    "    except ValueError:\n",
    "        print('Passages skipped')\n",
    "    \n",
    "    try:\n",
    "        if bleu_score != get_bleu_score(gt, gen, trunc = True):\n",
    "            n_mismatch += 1\n",
    "            # print('MISMATCH {}'.format(n_mismatch))\n",
    "            # print('Ge:', gen)\n",
    "            # print('GT:', gt)\n",
    "            # print(bleu_score, ' | ', get_bleu_score(gt, gen, trunc = True))\n",
    "            if bleu_score < 0.1:\n",
    "                n_very_small_blue += 1\n",
    "            \n",
    "        elif bleu_score < 0.1:\n",
    "            n_very_small_blue += 1\n",
    "            print('VERY SMALL BLEU {}'.format(n_very_small_blue))\n",
    "            print('Ge:', gen)\n",
    "            print('GT:', gt)\n",
    "            print(bleu_score)\n",
    "    except ValueError:\n",
    "        print('Passages skipped')\n",
    "\n",
    "print('AVG scores',get_bleu_score(atlas_valid_passage, atlas_generated_sequences))\n",
    "print('AVG scores TRUNC',get_bleu_score(atlas_valid_passage, atlas_generated_sequences, trunc = True))\n",
    "print('Very small bleu', n_very_small_blue)\n",
    "print('Mismatch', n_mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hippolytepilchen/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v2/5130cf1daf847c1bacee854a6ef1ca939e747fb2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Pre Embed: [8, 0]\n",
      "Prompt Post Embed: [10, 1]\n",
      "['\\n\\nMario Alberto Bortolazzi (born 12 January 1964) is a former professional footballer who played as a midfielder. He played for 12 seasons at A.C. Milan, winning the Serie A championship in 1991–92, and the Coppa Italia in 1993–94. He was transferred to Genoa C.F.C. for 500,000 lire, and made his debut on 25 September 1995, in a match against Fiorentina at', 'Mario Bortolazzi\\n\\nMario Bortolazzi (born 12 January 1965 in Genoa) is an Italian former professional football player and coach. He played 12 seasons in Serie A, for A.C. Milan, Atalanta, Fiorentina, and Hellas Verona. He played 246 games in Serie A, scoring 14 goals. 1990–91 season, he played 12 games in Serie B, for A.C. Milan. 1991–92 season,']\n"
     ]
    }
   ],
   "source": [
    "# Flipping attempts\n",
    "w_embeds = True\n",
    "temp = 0\n",
    "max_tokens = 128\n",
    "i_token_to_flip = -1\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "\n",
    "temp = [temp] * max_tokens   \n",
    "if max_tokens > i_token_to_flip >= 0:\n",
    "    temp[i_token_to_flip] = 1000\n",
    "    \n",
    "prompt = ''\n",
    "text_conditioning ='Mario Bortolazzi (born 10 January 1965, in Verona) is an Italian professional football coach and a former player, who played as a midfielder. \\\n",
    "    \\n\\nHe played 12 seasons (241 games, 14 goals) in the Serie A for ACF Fiorentina, A.C. Milan, Hellas Verona F.C., Atalanta B.C. and Genoa C.F.C.'\n",
    "        # \\n\\nIn his coaching career he has so far has always been an assistant to his former Milan teammate Roberto Donadoni.\\\n",
    "        #     \\n\\nHonours\\n\\n - Milan\\n - Serie A champion: 1987–88.\\n\\n - Genoa\\n - Anglo-Italian Cup winner: 1995–96.'\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "generated_sequence, attn_or_logprobs, embeddings = pipeline.generate(prompt_pre_embed = ['In other words, background: ',''], \n",
    "                                    prompt_post_embed = [' is just another way of saying: ',''],\n",
    "                                    text_conditioning = [text_conditioning]*2, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                    random_flip = i_token_to_flip,\n",
    "                                    device = device,\n",
    "                                    device_generation = device if torch.cuda.device_count() <= 1 else torch.device('cuda:1'),\n",
    "                                    return_embeddings = True)\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_passages = 20\n",
    "\n",
    "lim_toks = 128\n",
    "eval_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_valid.jsonl'\n",
    "train_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_train.jsonl'\n",
    "train_passage = []\n",
    "valid_passage = []\n",
    "\n",
    "with open(train_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        train_passage.append(pipeline.tokenizer.decode(pipeline.tokenizer.encode(json.loads(line)['text'].split('\\n\\n')[1], eos = True, bos = True)[:lim_toks]))\n",
    "  \n",
    "with open(eval_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        valid_passage.append(pipeline.tokenizer.decode(pipeline.tokenizer.encode(json.loads(line)['text'].split('\\n\\n')[1], eos = True, bos = True)[:lim_toks]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_embeds = True\n",
    "temp = 0\n",
    "max_tokens = 128\n",
    "i_token_to_flip = -1\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "\n",
    "temp = [temp] * max_tokens   \n",
    "if max_tokens > i_token_to_flip >= 0:\n",
    "    temp[i_token_to_flip] = 1000\n",
    "\n",
    "# prompt_prefix = \"Query: who wrote the song photograph by ringo starr\\nAnswer: Ringo Starr\\n\\nQuery: who is playing the halftime show at super bowl 2016\\nAnswer: Coldplay\\n\\nQuery: where was the world economic forum held this year\\nAnswer: Davos\\n\\nQuery: where are the giant redwoods located in california\\nAnswer: Humboldt County\\n\\nQuery: who has made the most premier league appearances\\nAnswer: Gareth Barry\\n\\nQuery: \"\n",
    "prompt_prefix = \"Query: \"\n",
    "prompts = ['who has most followers on instagram in world','who did the united states win its independence from', 'locations for the film an englishman who went up a hill', 'who is the valley of the dolls based on']\n",
    "prompts = [prompt_prefix + prompt + '\\nAnswer:' for prompt in prompts]\n",
    "\n",
    "conditioning = [\"This list contains the top 50 accounts with the most followers on the photo and video-sharing social platform Instagram. As of July 2019, the most followed user is Instagram's own account, with over 308 million followers. Cristiano Ronaldo is the most followed individual, with over 177 million followers. Fifteen accounts have exceeded 100 million followers on the site.\",\n",
    "                     \"During the American Revolution, the legal separation of the thirteen colonies from Great Britain in 1776 actually occurred on July 2, when the Second Continental Congress voted to approve a resolution of independence that had been proposed in June by Richard Henry Lee of Virginia declaring the United States independent from Great Britain's rule. After voting for independence, Congress turned its attention to the Declaration of Independence, a statement explaining this decision, which had been prepared by a Committee of Five, with Thomas Jefferson as its principal author. Congress debated and revised the wording of the Declaration, finally approving it two days later on July 4. A day earlier, John Adams had written to his wife Abigail\",\n",
    "                     'The village was a primary location for the making of the film \\\"The Englishman Who Went Up a Hill But Came Down a Mountain\\\", which starred Hugh Grant. The hilltop scenes were filmed on the Gyrn, the long hill that overlooks the village. It was also featured in \\\"Monk\\'s Hood\\\", an episode of \\\"The Cadfael Chronicles\\\"',\n",
    "                     'Valley of the Dolls is the first novel by American writer Jacqueline Susann. Published in 1966, the book was the biggest selling novel of its year. To date, it has sold more than 31 million copies, making it one of the best-selling works in publishing history.']\n",
    "\n",
    "# answers = ['Instagram','Great Britain',\"Llansilin in Powys\",[\"Judy Garland\", \"Carole Landis\", \"Dean Martin\", \"Ethel Merman\"]]\n",
    "\n",
    "# conditioning = 'Kyutai is a non-profit laboratory dedicated to open research in AI, founded in November 2023 by the iliad Group, CMA CGM and Schmidt Sciences.'\n",
    "# prompts =  prompt_prefix +'Query: when was founded Kyutai?\\nAnswer: '\n",
    "\n",
    "\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "pipeline.model.llm.pos_to_keep = []\n",
    "generated_sequence, logprobs = pipeline.generate(prompts = prompts, \n",
    "                                    text_conditioning = conditioning, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                    random_flip = i_token_to_flip,\n",
    "                                    device = device,\n",
    "                                    device_generation = device if torch.cuda.device_count() <= 1 else torch.device('cuda:1'),\n",
    "                                    return_embeddings = False)\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_att_weights, tokens = get_attention(generated_sequence[0], embeddings, pipeline.tokenizer, pipeline.model.llm, n_tokens = 20)\n",
    "# self_att_weights, tokens = get_attention('He played 12 seasons (243 games, 14 goals) in the Serie A for A.C. Milan, A.F.C. Fiorentina, Hellas Verona, Atalanta B.C. and Genoa C.F.C.', embeddings, pipeline.tokenizer, pipeline.model.llm, n_tokens = 20)\n",
    "\n",
    "head_view(self_att_weights, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_att_weights, tokens = get_attention(generated_sequence[0], embeddings, pipeline.tokenizer, pipeline.model.llm, n_tokens = 20)\n",
    "model_view([att[:,:,1:,1:] for att in self_att_weights], [tokens[0]] + tokens[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_per_head_att = [torch.mean(att, dim = 1, keepdim = True) for att in self_att_weights]\n",
    "overall_mean = torch.mean(torch.stack(self_att_weights), dim = 0)\n",
    "\n",
    "head_view(mean_per_head_att, tokens)\n",
    "# head_view([overall_mean], tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop)\n",
    "temperatures = [0, 0.5, 0.7, 1, 1.5]\n",
    "max_tokens = 150\n",
    "\n",
    "results_generation = {'0':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}}, \n",
    "                        '0.5':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}},\n",
    "                        '0.7':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}},\n",
    "                        '1':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}},\n",
    "                        '1.5':{'train': {'word_prompt':{}, 'empty_prompt':{}}, 'valid': {'word_prompt':{}, 'empty_prompt':{}}}}\n",
    "\n",
    "\n",
    "n_passages = len(train_passage)\n",
    "assert n_passages == len(valid_passage)\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f'Temperature: {temp}')    \n",
    "    generated_sequences = []\n",
    "    \n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = train_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [text.split(' ')[0] for text in passage], \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                     device = device,\n",
    "                                    device_generation = device if torch.cuda.device_count() <= 1 else torch.device('cuda:1'))\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)\n",
    "    results_generation[str(temp)]['train']['word_prompt'] = {'seq':generated_sequences}\n",
    "    print('Train Passage:', passage)\n",
    "    print('Train Generated:', generated_sequence)\n",
    "    generated_sequences = []\n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = train_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [''] * len(passage), \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                     device = device,\n",
    "                                    device_generation = device if torch.cuda.device_count() <= 1 else torch.device('cuda:1'))\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)    \n",
    "    results_generation[str(temp)]['train']['empty_prompt'] = {'seq':generated_sequences}\n",
    "    \n",
    "\n",
    "    generated_sequences = []\n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = valid_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [text.split(' ')[0] for text in passage], \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                     device = device,\n",
    "                                    device_generation = device if torch.cuda.device_count() <= 1 else torch.device('cuda:1'))\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)    \n",
    "    results_generation[str(temp)]['valid']['word_prompt'] = {'seq':generated_sequences}\n",
    "    \n",
    "    generated_sequences = []\n",
    "    for i in range(0, n_passages, max_batch_size):\n",
    "        passage = valid_passage[i:i+max_batch_size]\n",
    "        generated_sequence, logprobs = pipeline.generate(prompts = [''] * len(passage), \n",
    "                                    text_conditioning = passage, \n",
    "                                    temperature = temp, \n",
    "                                    max_tokens = max_tokens,\n",
    "                                    truncate_double_space = False,\n",
    "                                     device = device,\n",
    "                                    device_generation = device if torch.cuda.device_count() <= 1 else torch.device('cuda:1'))\n",
    "           \n",
    "        generated_sequences.extend(generated_sequence)    \n",
    "    results_generation[str(temp)]['valid']['empty_prompt'] = {'seq':generated_sequences}\n",
    "    print('Valid Passage:', passage)\n",
    "    print('Valid Generated:', generated_sequence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for temp in results_generation.keys():\n",
    "    for split in results_generation[temp].keys():\n",
    "        for prompt_type in results_generation[temp][split].keys():\n",
    "            generated_sequences = results_generation[temp][split][prompt_type]['seq']\n",
    "            if prompt_type == 'empty_prompt':\n",
    "                gt_passage = train_passage if split == 'train' else valid_passage\n",
    "                overlap = word_overlap(gt_passage, generated_sequences)\n",
    "                bleu_score = get_bleu_score(gt_passage, generated_sequences)\n",
    "            elif prompt_type == 'word_prompt':\n",
    "                gt_passage = train_passage if split == 'train' else valid_passage\n",
    "                gt_passage = [' '.join(text.split(' ')[1:]) for text in gt_passage]\n",
    "                overlap = word_overlap(gt_passage, generated_sequences)\n",
    "                bleu_score = get_bleu_score(gt_passage, generated_sequences)\n",
    "   \n",
    "            print(f'Temperature: {temp}, Split: {split}, Prompt Type: {prompt_type}, Overlap: {overlap}', 'Bleu Score:', bleu_score)\n",
    "            metrics.append({'temp': temp, 'split': split, 'prompt_type': prompt_type, 'overlap': overlap, 'bleu_score': bleu_score})\n",
    "            \n",
    "# with open(f'{ckpt_path}/results_generation.json', 'w') as f:\n",
    "#     json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_path = '/lustre/scwpod02/client/kyutai-interns/hippop/models/mistral_7B'\n",
    "#Must have a params json for pipeline\n",
    "\n",
    "# No embeddings:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/no_embed_bs16_lr5e-5Mistral7B88d0b42410aa4ec12025/checkpoints/checkpoint_002500'\n",
    "\n",
    "# Length tokens:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_512t_Mistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_005000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_256t_Mistral7Be9ffc00fa42bedbc50d0/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_128t_Mistral7B226729d875c65b331ef8/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_64t_Mistral7B9bbea1b3b8dc23079b04/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_32t_Mistral7Bccbc3f29d69bd124c6cf/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/SL_16t_Mistral7B7bc7dcc2ba28873eda96/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/mean_not_causal/checkpoints/checkpoint_007500'\n",
    "\n",
    "\n",
    "# # Continuation:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/continuation_Mistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_006000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/mean_finetuned_notcausal_continuationMistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_005500'\n",
    "\n",
    "# # Cross-Attention:\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_5_last_layersMistral7Bdbbb7faebb2f32cf20e9/checkpoints/checkpoint_010000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_fine_tuned_embedder_5_last_layersMistral7Bdbbb7faebb2f32cf20e9/checkpoints/checkpoint_007500'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_finetuned_notcausal_continuationMistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_005000'\n",
    "# ckpt_path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/cross_att_pretrained_continuationMistral7B20ed0018b2a84fba09c4/checkpoints/checkpoint_008500'\n",
    "\n",
    "with open(f'{ckpt_path}/params.json') as f:\n",
    "    params = json.load(f)\n",
    "print(params)\n",
    "\n",
    "model_name = 'Mistral7B' # Mistral7B, Llama3.2-3B, Gemma7B\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "w_embeds = True\n",
    "max_batch_size = 4\n",
    "\n",
    "# variant = '7b' if model_name == 'Gemma7B' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify old params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ckpt_path + '/params.json') as f:\n",
    "    params = json.load(f)\n",
    "print(params)\n",
    "# if 'do_pool'  not in params.keys():\n",
    "if 'n_truncated_layers' in params['pooling_module'].keys():\n",
    "    params['n_truncated_layers'] = params['pooling_module']['n_truncated_layers']\n",
    "    del params['pooling_module']['n_truncated_layers']\n",
    "    \n",
    "\n",
    "if params['cross_att'] is not None:\n",
    "    print('here')\n",
    "    params['normalize_embeddings'] = True if params['cross_att'] else False\n",
    "    if params['start_cross_att'] is None:\n",
    "        del params['start_cross_att']\n",
    "    else:\n",
    "        params['cross_att_layers'] = 32 - params[\"start_cross_att\"]\n",
    "        del params['start_cross_att']\n",
    "    params['do_pool'] = False if params['cross_att'] else True\n",
    "else:\n",
    "    params['do_pool'] = True\n",
    "print(params)\n",
    "with open(ckpt_path + '/params.json', 'w') as f:\n",
    "    json.dump(params, f)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tests:\n",
    "    print('Param:', param)\n",
    "    if param['w_embeds']:\n",
    "        pipeline.pipeline_args.w_embeds = True\n",
    "    else:\n",
    "        pipeline.pipeline_args.w_embeds = False\n",
    "    \n",
    "    final_valid_prompts = [passage.split(' ')[0] for passage in valid_passage][2] \n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    print('Prompt', final_valid_prompts, ' | Passage', text_valid_conditioning)\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  word', generated_sequence)\n",
    "    \n",
    "    final_valid_prompts = ['' for passage in train_passage][1]\n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  empty', generated_sequence)\n",
    "\n",
    "    final_train_prompts =  [passage.split(' ')[0] for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    print('Prompt', final_train_prompts, ' | Passage', text_train_conditioning)\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train word', generated_sequence)\n",
    "    final_train_prompts = ['' for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train empty', generated_sequence)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 information in the doc which enables to answer the question but not good response often in-context\n",
    "# 2 information in the doc which enables to answer the question and good response often in-context\n",
    "# 3 Hard negative passage\n",
    "# 4 Same\n",
    "\n",
    "# prompt_prefix = \"Query: who wrote the song photograph by ringo starr\\nAnswer: Ringo Starr\\n\\nQuery: who is playing the halftime show at super bowl 2016\\nAnswer: Coldplay\\n\\nQuery: where was the world economic forum held this year\\nAnswer: Davos\\n\\nQuery: where are the giant redwoods located in california\\nAnswer: Humboldt County\\n\\nQuery: who has made the most premier league appearances\\nAnswer: Gareth Barry\\n\\nQuery: \"\n",
    "# prompts = ['who has most followers on instagram in world','who did the united states win its independence from', 'locations for the film an englishman who went up a hill', 'who is the valley of the dolls based on']\n",
    "# final_prompts = [prompt_prefix + prompt + '\\nAnswer:' for prompt in prompts]\n",
    "\n",
    "# text_conditioning = [\"This list contains the top 50 accounts with the most followers on the photo and video-sharing social platform Instagram. As of July 2019, the most followed user is Instagram's own account, with over 308 million followers. Cristiano Ronaldo is the most followed individual, with over 177 million followers. Fifteen accounts have exceeded 100 million followers on the site.\",\n",
    "#                      \"During the American Revolution, the legal separation of the thirteen colonies from Great Britain in 1776 actually occurred on July 2, when the Second Continental Congress voted to approve a resolution of independence that had been proposed in June by Richard Henry Lee of Virginia declaring the United States independent from Great Britain's rule. After voting for independence, Congress turned its attention to the Declaration of Independence, a statement explaining this decision, which had been prepared by a Committee of Five, with Thomas Jefferson as its principal author. Congress debated and revised the wording of the Declaration, finally approving it two days later on July 4. A day earlier, John Adams had written to his wife Abigail\",\n",
    "#                      'The village was a primary location for the making of the film \\\"The Englishman Who Went Up a Hill But Came Down a Mountain\\\", which starred Hugh Grant. The hilltop scenes were filmed on the Gyrn, the long hill that overlooks the village. It was also featured in \\\"Monk\\'s Hood\\\", an episode of \\\"The Cadfael Chronicles\\\"',\n",
    "#                      'Valley of the Dolls is the first novel by American writer Jacqueline Susann. Published in 1966, the book was the biggest selling novel of its year. To date, it has sold more than 31 million copies, making it one of the best-selling works in publishing history.']\n",
    "\n",
    "# answers = ['Instagram','Great Britain',\"Llansilin in Powys\",[\"Judy Garland\", \"Carole Landis\", \"Dean Martin\", \"Ethel Merman\"]]\n",
    "\n",
    "n_passages = 4\n",
    "eval_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_valid.jsonl'\n",
    "train_data = '/lustre/scwpod02/client/kyutai-interns/datasets/modular_finetuning/enwiki-20220120_train.jsonl'\n",
    "train_passage = []\n",
    "valid_passage = []\n",
    "with open(train_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        train_passage.append(json.loads(line)['text'].split('\\n\\n')[1])\n",
    "        \n",
    "with open(eval_data, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == n_passages:\n",
    "            break\n",
    "        valid_passage.append(json.loads(line)['text'].split('\\n\\n')[1])\n",
    "        \n",
    "tests = [{'w_embeds': True, 'temperature': 0 },  {'w_embeds': True, 'temperature': 0.7 }, {'w_embeds': False, 'temperature': 0.7 }]\n",
    "# print('Train passage:', train_passage)\n",
    "# print('Valid passage:', valid_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioning = ['Kyutai is a non-profit laboratory dedicated to open research in AI, founded in November 2023 by the iliad Group, CMA CGM and Schmidt Sciences. Launched with an initial team of six leading scientists, who have all worked with Big Tech labs in the USA, Kyutai continues to recruit at the highest level, and also offers internships to research Master’s degree students.']*4\n",
    "prompts = ['who are the founders of Kyutai?', 'when was Kyutai founded?', 'how many scientists were in the initial team?', 'what does Kyutai offer to research Master’s degree students?']\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "generated_sequence = pipeline.generate(prompts = prompts,\n",
    "                                      text_conditioning = conditioning,\n",
    "                                      temperature = 0.5, \n",
    "                                      max_tokens =200,\n",
    "                                      truncate_double_space = False)\n",
    "# random_flip, put the number of the token to flip. \n",
    "print(generated_sequence)\n",
    "\n",
    "if w_embeds:\n",
    "    pipeline.pipeline_args.w_embeds = True\n",
    "else:\n",
    "    pipeline.pipeline_args.w_embeds = False\n",
    "generated_sequence, logprobs = pipeline.generate(prompts = ['who has most followers on Instagram in world?'],\n",
    "                                      text_conditioning = [\"This list contains the top 50 accounts with the most followers on the photo and video-sharing social platform Instagram. As of July 2019, the most followed user is Instagram's own account, with over 308 million followers. Cristiano Ronaldo is the most followed individual, with over 177 million followers.\"],\n",
    "                                      temperature = 0.4, \n",
    "                                      max_tokens =200,\n",
    "                                      truncate_double_space = False)\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuation\n",
    "for param in tests:\n",
    "    print('Param:', param)\n",
    "    if param['w_embeds']:\n",
    "        pipeline.pipeline_args.w_embeds = True\n",
    "    else:\n",
    "        pipeline.pipeline_args.w_embeds = False\n",
    "    \n",
    "    final_valid_prompts = [passage[100:].split(' ')[0] for passage in valid_passage][2] \n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    print('Passage', text_valid_conditioning, ' | Truth', [passage[100:200] for passage in valid_passage][2] )\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  word', generated_sequence)\n",
    "    \n",
    "    final_valid_prompts = ['' for passage in train_passage][2]\n",
    "    text_valid_conditioning = [passage[:100] for passage in valid_passage][2]\n",
    "    generated_sequence = pipeline.generate(prompts = final_valid_prompts, \n",
    "                                        text_conditioning = text_valid_conditioning, \n",
    "                                        temperature = param['temperature'], \n",
    "                                        max_tokens = max_tokens,\n",
    "                                        truncate_double_space = False)\n",
    "    print('Valid  empty', generated_sequence)\n",
    "\n",
    "    final_train_prompts =  [passage[100:].split(' ')[0] for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    print('Passage', text_train_conditioning, ' | Truth', [passage[100:200] for passage in train_passage][1] )\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train word', generated_sequence)\n",
    "    final_train_prompts = ['' for passage in train_passage][1] \n",
    "    text_train_conditioning = [passage[:100] for passage in train_passage][1]\n",
    "    generated_sequence = pipeline.generate(prompts = final_train_prompts, \n",
    "                                       text_conditioning = text_train_conditioning, \n",
    "                                       temperature = param['temperature'], \n",
    "                                       max_tokens = max_tokens,\n",
    "                                       truncate_double_space = False)\n",
    "    print('Train empty', generated_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tested\n",
    "# run_name = '128_SL_FN_False_0_MLP_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_24_CAL_False_SKV_True_DB'\n",
    "\n",
    "# Finished runs:\n",
    "\n",
    "# run_name = '128_SL_FN_Truemean_1_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB' # 008500\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_True_CA_5_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_True_CA_24_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_1_MLP_4_TRUNC_True_CA_5_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_1_MLP_4_TRUNC_True_CA_24_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_4_TRUNC_True_CA_5_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_4_TRUNC_True_CA_24_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truelatent_attention_0_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truelatent_attention_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Trueeos_0_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Trueeos_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truereversed_latent_atttention_0_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truereversed_latent_attention_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_8_TRUNC_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_8_TRUNC_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_True_CA_16_CAL_False_SKV_True_DB_dist_process'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_4_TRUNC_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_3_MLP_8_TRUNC_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_4_TRUNC_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_Truemean_0_MLP_8_TRUNC_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_True_CA_5_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_True_CA_24_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_1_MLP_True_CA_5_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_1_MLP_True_CA_16_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_1_MLP_True_CA_24_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_0_MLP_True_CA_5_CAL_False_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_True_CA_16_CAL_False_SKV_False_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_False_CA_False_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_True_CA_16_CAL_True_SKV_True_DB'\n",
    "# run_name = '128_SL_FN_False_3_MLP_True_CA_16_CAL_False_SKV_True_DB_dist_process'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/lustre/scwpod02/client/kyutai-interns/hippop/tmp/ToyDecompressingTests_LLM_FT_MaxEmb_1_one_over_2/checkpoints/checkpoint_020000/instruct.json'\n",
    "\n",
    "dico = {'do': True, 'kl_pretraining': False, 'alpha': 1.0, 'tune_llm': True, 'tune_embedder': False, 'decompress_usage': 'one_over_two_reconstruction'}\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(dico, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
